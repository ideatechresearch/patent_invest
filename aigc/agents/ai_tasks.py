import igraph as ig
import json, time, random
from enum import Enum as PyEnum
from collections import defaultdict
import asyncio
import queue
from redis.asyncio import Redis, StrictRedis
from typing import Dict, List, Tuple, Union, Iterable, Callable
from threading import Thread
import uuid
import zmq, zmq.asyncio
from config import Config

QUEUE_NAME: str = "message_queue"

_redis_client: Redis = None  # StrictRedis(host='localhost', port=6379, db=0)
Task_graph = ig.Graph(directed=True)  # åˆ›å»ºæœ‰å‘å›¾


def get_redis() -> Redis:
    global _redis_client
    if _redis_client is None:
        _redis_client = Redis(host=Config.REDIS_HOST, port=Config.REDIS_PORT, db=0,
                             decode_responses=True  # è‡ªåŠ¨è§£ç ä¸ºå­—ç¬¦ä¸²
                             )
    return _redis_client


async def shutdown_redis():
    if _redis_client:
        await _redis_client.close()


async def do_job_by_lock(func_call: Callable, redis_key: str = None, lock_timeout: int = 600, **kwargs):
    redis = get_redis()
    if not redis:
        await func_call(**kwargs)
        return

    if not redis_key:
        redis_key = f'lock:{func_call.__name__}'
    lock_value = str(time.time())
    lock_acquired = await redis.set(redis_key, lock_value, nx=True, ex=lock_timeout)
    if not lock_acquired:
        print(f"âš ï¸ åˆ†å¸ƒå¼é”å·²è¢«å ç”¨ï¼Œè·³è¿‡ä»»åŠ¡: {func_call.__name__}")
        return

    try:
        print(f"ğŸ”’ è·å–é”æˆåŠŸï¼Œå¼€å§‹æ‰§è¡Œä»»åŠ¡: {func_call.__name__}")
        await func_call(**kwargs)
    except Exception as e:
        print(f"âš ï¸ ä»»åŠ¡æ‰§è¡Œå‡ºé”™: {func_call.__name__} -> {e}")
    finally:
        current_lock_value = await redis.get(redis_key)
        if current_lock_value and current_lock_value == lock_value:
            await redis.delete(redis_key)


class TaskEdge:
    source: str  # ä¾èµ–çš„èµ·å§‹ä»»åŠ¡
    target: str  # è¢«è§¦å‘çš„ä»»åŠ¡
    condition: str  # è¾¹ä¸Šçš„è§¦å‘æ¡ä»¶ï¼ˆä¸æºä»»åŠ¡çš„çŠ¶æ€ç›¸å…³),["done",{"deadline": time.time() + 60}]
    # type: str  # status_conditionåŸºäºä»»åŠ¡çš„çŠ¶æ€è§¦å‘,event_trigger,åŸºäºæŸä¸ªä»»åŠ¡è§¦å‘çš„äº‹ä»¶æ¥æ¿€æ´»ä»»åŠ¡
    trigger_time: dict = None  # absolute,relative,[None, {"relative": 5}]
    trigger_event = None  # ä»»åŠ¡è§¦å‘äº‹ä»¶,Noneæ— ä¾èµ–
    rule = None  # å¤æ‚æ¡ä»¶,å‡½æ•°æˆ–å¤æ‚çš„é€»è¾‘åˆ¤æ–­

    def __init__(self, source, target, condition, trigger_time=None, trigger_event=None, rule=None):
        self.source = source
        self.target = target
        self.condition = condition
        self.trigger_time = trigger_time
        self.trigger_event = trigger_event
        self.rule = rule


# for task_id, attributes in Task_queue.items():
# æ·»åŠ èŠ‚ç‚¹åˆ°å›¾ä¸­
def set_task_node(task_id, attributes):
    nodes = Task_graph.vs["name"] if "name" in Task_graph.vs.attributes() else []
    if task_id in nodes:  # Task_graph
        # æ›´æ–°å·²æœ‰èŠ‚ç‚¹å±æ€§
        node_idx = Task_graph.vs.find(name=task_id).index
        Task_graph.vs[node_idx].update_attributes(attributes)

        # attributes= {**Task_graph.nodes[task_id], **Task_queue[task_id]}
        # Task_graph.nodes[task_id].update(attributes)
    else:
        Task_graph.add_vertex(name=task_id, **attributes)
        # Task_graph.add_node(task_id, **Task_queue[task_id])è‡ªåŠ¨å¤„ç†ä¸å­˜åœ¨çš„èŠ‚ç‚¹


def update_task_status(task_id, new_status):
    task_index = Task_graph.vs.find(name=task_id).index
    Task_graph.vs[task_index]["status"] = new_status


def set_task_condition(edges, conditions=["done"]):
    for (source, target), condition in zip(edges, conditions):
        if source in Task_graph.vs["name"] and target in Task_graph.vs["name"]:
            Task_graph.add_edge(source, target, condition=condition)


# æ£€æŸ¥ä¾èµ–å¹¶è§¦å‘ä»»åŠ¡
def check_and_trigger_tasks(graph):
    for edge in graph.es:
        source_task = graph.vs.find(name=edge.source)
        target_task = graph.vs.find(name=edge.target)

        if target_task["status"] == "pending":
            condition = edge["condition"]
            event_ready = 0
            # çŠ¶æ€æ¡ä»¶
            if isinstance(condition, str) and source_task["status"] == condition:
                trigger_event = edge.get("trigger_event", None)
                trigger_time = edge.get("trigger_time", None)
                # ä»»åŠ¡çŠ¶æ€å˜åŒ–åè§¦å‘äº‹ä»¶é©±åŠ¨çš„ä»»åŠ¡è¾¹æˆ–è€…ä»»åŠ¡Aå®Œæˆæ—¶è§¦å‘å¤šä¸ªäº‹ä»¶
                event_ready = 1 if not trigger_event else source_task.get("event") == trigger_event
                # æ£€æŸ¥æ—¶é—´æ¡ä»¶>
                if trigger_time:
                    if "absolute" in trigger_time:
                        event_ready = time.time() >= trigger_time["absolute"]
                    elif "relative" in trigger_time:
                        event_ready = time.time() >= source_task.get("start_time", 0) + trigger_time["relative"]
            # æ—¶é—´æ¡ä»¶<
            elif isinstance(condition, dict) and "deadline" in condition:
                if time.time() <= condition["deadline"]:
                    event_ready = 1 << 1
            # è‡ªå®šä¹‰æ¡ä»¶
            elif callable(condition) and condition():
                event_ready = 1 << 2

            if event_ready:
                target_task["status"] = "ready"
                print(f"Task {target_task['name']} is now ready.")


# ä»»åŠ¡æ‰§è¡Œä¸»å¾ªç¯
def task_execution_loop(graph):
    while True:
        # æŸ¥æ‰¾çŠ¶æ€ä¸º ready çš„ä»»åŠ¡å¹¶æ‰§è¡Œ
        ready_tasks = [v for v in graph.vs if v["status"] == "ready"]
        if not ready_tasks:
            break  # æ— å¯æ‰§è¡Œä»»åŠ¡æ—¶é€€å‡º
        for task in ready_tasks:
            print(f"Executing task {task['name']}...")
            time.sleep(1)  # æ¨¡æ‹Ÿæ‰§è¡Œæ—¶é—´
            task["status"] = "done"  # 'completed'
            print(f"Task {task['name']} is now done.")

        # æ£€æŸ¥å¹¶è§¦å‘æ–°çš„ä»»åŠ¡
        check_and_trigger_tasks(graph)

        time.sleep(1)


def get_children(g, node):
    # g.successors(node.index)
    return [g.vs[neighbor]["name"] for neighbor in g.neighbors(node, mode="OUT")]


def get_parent(g, node):
    # g.predecessors(node.index)
    neighbors = g.neighbors(node, mode="IN")
    return g.vs[neighbors[0]]["name"] if neighbors else None


def export_to_json_from_graph(graph, filename):
    data = {"nodes": [{"id": v.index, **v.attributes()} for v in graph.vs],
            "edges": [{"source": e.source, "target": e.target, **e.attributes()} for e in graph.es], }
    with open(filename, "w") as f:
        json.dump(data, f, indent=4)

    # graph.write_pickle("graph.pkl")


def import_to_graph_from_json(filename):
    with open(filename, "r") as f:
        data = json.load(f)

    g = ig.Graph(directed=True)  # ig.Graph.TupleList(
    g.add_vertices(len(data["nodes"]))
    # g.vs["name"] = [node["id"] for node in data["nodes"]]
    # ä¸ºèŠ‚ç‚¹è®¾ç½®å±æ€§
    for idx, node in enumerate(data["nodes"]):
        g.vs[idx].update_attributes(node)  # node.items()
    g.add_edges([(edge["source"], edge["target"]) for edge in data["edges"]])  # [("task1", "task2")]

    # ä¸ºè¾¹è®¾ç½®å±æ€§
    for idx, edge in enumerate(data["edges"]):
        # è·³è¿‡ source å’Œ target å±æ€§
        g.es[idx].update_attributes({k: v for k, v in edge.items() if k not in ["source", "target"]})
        # g.es[idx][key] = value

    # g.es["condition"] = ["done"]
    return g


class WebSearchGraph:
    def __init__(self):

        # åˆå§‹åŒ–èŠ‚ç‚¹å†…å®¹å­—å…¸
        self.nodes: Dict[str, Dict[str, str]] = {}
        # åˆå§‹åŒ–é‚»æ¥è¡¨
        self.adjacency_list: Dict[str, List[dict]] = defaultdict(list)
        self.task_queue = queue.Queue()
        self.n_active_tasks = 0

    async def add_root_node(self, node_content: str, node_name: str = 'root'):
        # æ·»åŠ æ ¹èŠ‚ç‚¹
        self.nodes[node_name] = dict(content=node_content, type="root")
        # åœ¨å›¾ä¸­æ·»åŠ èŠ‚ç‚¹

        self.adjacency_list[node_name] = []
        return node_name

    async def add_node(self, node_name: str, node_content: str):
        # æ·»åŠ å­é—®é¢˜èŠ‚ç‚¹
        self.nodes[node_name] = dict(content=node_content, type="search")

        self.adjacency_list[node_name] = []

        # å¤„ç†çˆ¶èŠ‚ç‚¹ï¼ŒæŸ¥æ‰¾ç›¸å…³çš„å†å²ä¸Šä¸‹æ–‡
        parent_response = []
        for start_node, adj in self.adjacency_list.items():
            for neighbor in adj:
                if (node_name == neighbor["name"]  # åˆ¤æ–­æ˜¯å¦æœ‰è¿æ¥,æ˜¯å¦æ˜¯å½“å‰èŠ‚ç‚¹çš„çˆ¶èŠ‚ç‚¹ï¼Œå¹¶ä¸”è¯¥çˆ¶èŠ‚ç‚¹åŒ…å« response ä¿¡æ¯
                        and start_node in self.nodes and "response" in self.nodes[start_node]):
                    parent_response.append(
                        dict(question=self.nodes[start_node]["content"], answer=self.nodes[start_node]["response"]))

        await self._async_node_stream(node_name, node_content)

        self.n_active_tasks += 1  # f"{node_name}-{node_content}"
        return self.n_active_tasks

    async def _async_node_stream(self, node_name: str, node_content: str, parent_response: List[dict]):
        """æ‰§è¡Œå¼‚æ­¥æœç´¢"""
        cfg = {"search_config": "value"}  # é…ç½®æœç´¢
        session_id = random.randint(0, 999999)  # ä¼šè¯ID
        agent = None

        try:
            # æ¨¡æ‹Ÿæœç´¢è¿‡ç¨‹
            searcher_message = "mock_search_message"  # å‡è®¾çš„æœç´¢æ¶ˆæ¯
            self.nodes[node_name]["response"] = searcher_message  # æ›´æ–°èŠ‚ç‚¹å“åº”
            self.nodes[node_name]["session_id"] = session_id
            self.task_queue.put((node_name, self.nodes[node_name]))  # å°†ç»“æœæ”¾å…¥é˜Ÿåˆ—
        except Exception as exc:
            self.task_queue.put((exc, None))

    async def add_response_node(self, node_name: str = 'response'):
        # æ·»åŠ å›å¤èŠ‚ç‚¹
        self.nodes[node_name] = dict(content='Search completed, thought response added.', type="response")
        # self.adjacency_list[node_name] = []
        self.task_queue.put((node_name, self.nodes[node_name], []))

    async def add_edge(self, start_node: str, end_node: str):
        self.adjacency_list[start_node].append(dict(id=str(uuid.uuid4()), name=end_node, state=2))

        self.task_queue.put((start_node, self.nodes[start_node], self.adjacency_list[start_node]))

    async def reset(self):
        # é‡ç½®å›¾å’ŒèŠ‚ç‚¹
        self.nodes.clear()
        self.adjacency_list.clear()

    def node(self, node_name: str):
        # è·å–èŠ‚ç‚¹ä¿¡æ¯
        if node_name in self.nodes:
            return self.nodes[node_name].copy()

        return None

    def graph(self):
        """æ ¹æ®èŠ‚ç‚¹ä¿¡æ¯å’Œé‚»æ¥è¡¨ç”Ÿæˆå›¾
        nodes = {
            "root": {"content": "What is AI?", "type": "root"},
            "node1": {"content": "What is machine learning?", "type": "search"},
            "node2": {"content": "What is deep learning?", "type": "search"}
        }

        adjacency_list = {
            "root": [{"name": "node1"}, {"name": "node2"}],
            "node1": [{"name": "node2"}],
            "node2": []
        }

        Returns:
            ig.Graph: è¿”å›ç”Ÿæˆçš„å›¾å¯¹è±¡
        """
        # åˆå§‹åŒ–å›¾å¯¹è±¡
        graph = ig.Graph(directed=True)  # åˆ›å»ºæœ‰å‘å›¾

        # æ·»åŠ èŠ‚ç‚¹åˆ°å›¾ä¸­
        node_names = list(self.nodes.keys())  # è·å–èŠ‚ç‚¹åç§°åˆ—è¡¨
        graph.add_vertices(node_names)  # æ·»åŠ å›¾çš„æ‰€æœ‰èŠ‚ç‚¹

        # ä¸ºæ¯ä¸ªèŠ‚ç‚¹æ·»åŠ å±æ€§
        for node_name, node_data in self.nodes.items():
            graph.vs[node_name]["content"] = node_data["content"]
            graph.vs[node_name]["type"] = node_data.get("type", "search")

        # æ·»åŠ è¾¹åˆ°å›¾ä¸­
        for start_node, neighbors in self.adjacency_list.items():
            for neighbor in neighbors:
                # æ ¹æ®é‚»æ¥è¡¨å»ºç«‹è¿æ¥ï¼Œæ·»åŠ è¾¹
                graph.add_edge(start_node, neighbor["name"])

        return graph


_StringLikeT = Union[bytes, str, memoryview]


def list_or_args_keys(keys: Union[_StringLikeT, Iterable[_StringLikeT]],
                      args: Tuple[_StringLikeT, ...] = None) -> List[_StringLikeT]:
    # å°† keys å’Œ args åˆå¹¶æˆä¸€ä¸ªæ–°çš„åˆ—è¡¨
    # returns a single new list combining keys and args
    try:
        iter(keys)
        # a string or bytes instance can be iterated, but indicates
        # keys wasn't passed as a list
        if isinstance(keys, (bytes, str)):
            keys = [keys]
        else:
            keys = list(keys)  # itertools.chain.from_iterable(keys)
    except TypeError:
        keys = [keys]
    if args:
        keys.extend(args)
    return keys


# async def setr(key, value, ex=None):
#     redis = get_redis()
#     await redis.set(name=key, value=value, ex=ex)
#     # await redis.delete(key) redis.get(key, encoding='utf-8')

# pip install celery[redis]
# celery = Celery('tasks', broker='redis://localhost:6379/0') #Celery ä»»åŠ¡
# message_queue = asyncio.Queue()
# å¼‚æ­¥ç”Ÿäº§è€…
async def producer(messages):
    # rpush, hset, ç­‰å†™æ“ä½œ
    redis = get_redis()
    await redis.rpush(QUEUE_NAME, *messages)  # å¼‚æ­¥æ”¾å…¥é˜Ÿåˆ—
    # for message in messages:
    #     await redis.hset("task_status", message, "pending")
    #     # await message_queue.put(message)
    #     print(f"Produced: {message}")
    #     await asyncio.sleep(1)
    # finally:
    #     await redis.close()


# å¼‚æ­¥æ¶ˆè´¹è€…
async def consumer():
    # blpop, get, ç­‰è¯»æ“ä½œ
    redis = get_redis()
    while True:
        message = await redis.blpop(QUEUE_NAME, timeout=10)  # å¼‚æ­¥é˜»å¡æ¶ˆè´¹ Left Pop
        if message:
            q, item = message
            task = item.decode('utf-8')
            print(f"Consumed: {task}")  # message[1].decode()
            # data = json.loads(task)
            # message = await message_queue.get()
            # print(f"Consumed: {message}")
            # message_queue.task_done()  # æ ‡è®°ä»»åŠ¡å®Œæˆ
            yield task

            await redis.hset("task_status", task, "completed")
        else:
            break
    # await redis.close()


# async for task in consumer():
#     await asyncio.sleep(1)
# asyncio.create_task(

class MessageZeroMQ:

    def __init__(self, pull_port="7556", push_port="7557", req_port="7555", process_callback=None):
        self.context = zmq.asyncio.Context(io_threads=2)  # zmq.Context()

        # è®¾ç½®æ¥æ”¶æ¶ˆæ¯çš„ socket
        self.pull_socket = self.context.socket(zmq.PULL)
        self.pull_socket.bind(f"tcp://*:{pull_port}")  # ç»‘å®šæ¥æ”¶ç«¯å£

        # è®¾ç½®å‘é€æ¶ˆæ¯çš„ socket
        self.push_socket = self.context.socket(zmq.PUSH)
        self.push_socket.connect(f"tcp://localhost:{push_port}")  # è¿æ¥åˆ° Java çš„æ¥æ”¶ç«¯å£

        # è®¾ç½® REQ socket ç”¨äºè¯·æ±‚-å“åº”æ¨¡å¼
        self.req_socket = self.context.socket(zmq.REQ)  # zmq.DEALER
        if req_port:
            self.req_socket.connect(f"tcp://localhost:{req_port}")  # è¿æ¥åˆ°æœåŠ¡ç«¯

        self.process_callback = process_callback or self.default_process_message
        # self.push_socket.send_string('topic1 Hello, world!')

    def __del__(self):
        self.context.destroy(linger=0)

    @staticmethod
    def default_process_message(message):
        # å¤„ç†é€»è¾‘
        print(f"Processing message: {message}")
        # å¯¹æ¶ˆæ¯è¿›è¡ŒæŸäº›å¤„ç†åéœ€è¦å°†å…¶è½¬å‘å› Java
        return f"Processed: {message}"

    async def send_request(self, message: str = "Hello, server!", topic: str = 'Request'):
        """
        ä½¿ç”¨ REQ socket ä¸»åŠ¨å‘é€æ¶ˆæ¯å¹¶æ¥æ”¶å“åº”,ä¸»åŠ¨è¯·æ±‚-å“åº”
        """
        await self.req_socket.send_string(f'{topic} {message}')
        print(f"Sent request: {message} under topic: {topic}")
        response = await self.req_socket.recv_string()
        print(f"Received response: {response}")
        return response

    async def call_service(self, data):
        """
        ä½¿ç”¨ REQ socket å‘é€ JSON æ•°æ®å¹¶æ¥æ”¶ JSON å“åº” zmq.Context()
        """
        self.req_socket.send_json(data)
        response = self.req_socket.recv_json()
        # message = await self.req_socket.recv()
        # response = json.loads(message.decode())
        print(f"Received response: {response}")
        return response

    # ä¸»åŠ¨å‘é€æ¶ˆæ¯åˆ° ZeroMQ
    async def send_message(self, message: str, topic: str = "Default"):
        await self.push_socket.send_string(f'{topic} {message}', flags=zmq.DONTWAIT, encoding='utf-8')
        print(f"Sent message: {message}")

    async def send_data(self, data=b'Hello in binary'):
        await self.push_socket.send(data, flags=zmq.DONTWAIT, copy=True, track=False)

    async def recv_messages(self):
        while True:
            # å°†æ¥æ”¶åˆ°çš„æ¶ˆæ¯ yield å‡ºå»
            message = await self.pull_socket.recv_string()
            yield message

    async def stream_start(self):
        async for message in self.recv_messages():
            print(f"Received from ZeroMQ: {message}")
            processed_msg = self.process_callback(message)
            await self.send_message(processed_msg, topic="Processed")

    async def start(self):
        # ä½¿ç”¨ asyncio å’Œ run_in_executor è¿›è¡Œé˜»å¡æ“ä½œ
        # loop = asyncio.get_event_loop()

        while True:
            # æ¥æ”¶æ¶ˆæ¯
            message = await self.pull_socket.recv_string()
            print(f"Received from ZeroMQ: {message}")

            # å¤„ç†æ¶ˆæ¯
            processed_msg = self.process_callback(message)

            # å°†å¤„ç†åçš„æ¶ˆæ¯å‘é€
            await self.push_socket.send_string(processed_msg)
            print(f"Sent processed message back.")


#
# import pika
# https://www.rabbitmq.com/tutorials
#
# # Pika is a RabbitMQ,å‘é€æ¶ˆæ¯åˆ° RabbitMQ
# def send_event(event_data):
#     connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))
#     channel = connection.channel()
#     channel.queue_declare(queue='event_queue')
#
#     channel.basic_publish(exchange='', routing_key='event_queue',
#                           body=event_data)
#     connection.close()
#
#
# # ç›‘å¬æ¶ˆæ¯å¹¶è°ƒç”¨æœåŠ¡
# def listen_for_events(callback):
#     connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))
#     channel = connection.channel()
#     channel.queue_declare(queue='event_queue')
#
#     channel.basic_consume(queue='event_queue', on_message_callback=callback, auto_ack=True)
#
#     print('Waiting for events...')
#     channel.start_consuming()


if __name__ == "__main__":
    import sys

    # if sys.platform.startswith('win'):
    #     asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    #
    # message_zero_mq = MessageZeroMQ()  # åˆ›å»ºæ¶ˆæ¯å¤„ç†å™¨å®ä¾‹
    # asyncio.run(message_zero_mq.stream_start())
    # asyncio.run(message_zero_mq.start())

    # è¿è¡Œå¼‚æ­¥ä»»åŠ¡
    # async def main():
    #     await asyncio.gather(producer([f"Message {i}" for i in range(5)]), consumer())
    #     # redis = Redis(host="localhost", port=6379)
    #     # await redis.set("key", "value")
    #     # value = await redis.get("key")
    #     # print(value.decode())  # è¾“å‡º: value
    #     # await redis.close()
    #
    #
    # asyncio.run(main())
