import requests
import logging
import json
import httpx
import re, hashlib, time
import asyncio
from enum import Enum

try:
    from openai import OpenAI, AsyncOpenAI
except ImportError:
    pass

try:
    import aiohttp
except ImportError:
    pass

AI_API_KEYS = {'moonshot': "",
               'aigc': "token-abc123"}
AIGC_HOST = 'aigc'

USER_ID = 'script'


class ModelNameEnum(str, Enum):
    turbo = "qwen-turbo"  # 1M qwen:qwen2.5-32b-instruct
    long = "qwen-long"  # 10M
    plus = "qwen-plus"  # 128K qwen:qwq-plus
    coder = "qwen-coder-plus"  # 128K
    max = "qwen-max"  # 128K
    chat = "deepseek-chat"  # 64K
    think = "deepseek-reasoner"  # 128K
    distill = "deepseek-r1-distill-qwen-32b"  # 32K
    moonshot = "moonshot:moonshot-v1-8k"


DEFAULT_MODEL_NAME = ModelNameEnum.plus.value
ANALYSIS_MODEL_NAME = ModelNameEnum.chat.value  # "deepseek:deepseek-chat"


class Res:
    def set_result(self, context, code):
        self.context = context
        self.res_code = code


class RunMethod:
    def __init__(self):
        self.session = requests.Session()  # ä½¿ç”¨sessionä¿æŒè¿æ¥
        self.result = Res()

    def _log_request(self, method, url, data, headers):
        logging.info(f'{method.upper()} method,request url={url}')
        try:
            data = json.dumps(json.loads(data), ensure_ascii=False)
        except:
            pass
        logging.info(f'{method.upper()} method,request data={data}')
        if headers:
            logging.info(f'{method.upper()} method,request headers={headers}')

    def _log_response(self, method, res):
        logging.info(f'{method.upper()} method,response status={res.status_code}')
        logging.info(f'{method.upper()} method,response content={res.text}')

    def _make_request(self, method, url, data=None, headers=None, verify=False, **kwargs):
        self._log_request(method, url, data, headers)

        try:
            if method == 'post':
                res = self.session.post(url, data=data, headers=headers, verify=verify, **kwargs)
            elif method == 'get':
                res = self.session.get(url, params=data, headers=headers, verify=verify, **kwargs)
            elif method == 'put':
                res = self.session.put(url, data=data, headers=headers, verify=verify, **kwargs)
            else:
                raise ValueError(f"Unsupported method: {method}")

            self._log_response(method, res)
            return res
        except requests.RequestException as e:
            logging.error(f'{method.upper()}æ–¹æ³•è¯·æ±‚å¤±è´¥: {e}')
            raise

    def post_main(self, url, data, headers=None, verify=False, **kwargs):
        return self._make_request('post', url, data, headers, verify, **kwargs)

    def get_main(self, url, data=None, headers=None, verify=False, **kwargs):
        return self._make_request('get', url, data, headers, verify, **kwargs)

    def put_main(self, url, data, headers=None, verify=False, **kwargs):
        return self._make_request('put', url, data, headers, verify, **kwargs)

    @classmethod
    def _request_helper(cls, url, body, headers, timeout, stream=False):
        try:
            return cls.post_main(url, json.dumps(body), headers=headers, timeout=timeout, stream=stream)
        except Exception as e:
            return str(e)

    def run_main(self, application, method, url, data=None, header=None):
        if application == "jira":
            application = "https://j.ideatech.info"
        if application == "confluence":
            application = "https://c.ideatech.info"

        # Log().info('è¯·æ±‚æ–¹æ³•çš„request data=' + str(data))
        try:
            if method == 'post':
                res = self.post_main(application + url, data, header)
                if res.status_code == 500:
                    context = ''
                else:
                    context = res.text
                res_code = res.status_code
                self.result.set_result(context, res_code)
                res.close()
                return self.result  # return res
            if method == "get":
                res = self.get_main(application + url, data, header)
                if res.status_code == 500:
                    context = ''
                else:
                    context = res.text
                res_code = res.status_code
                self.result.set_result(context, res_code)
                res.close()
                return self.result  # return res
            if method == "put":
                res = self.put_main(application + url, data, header)
                if res.status_code == 500:
                    context = ''
                else:
                    context = res.text
                res_code = res.status_code
                self.result.set_result(context, res_code)
                res.close()
                return self.result  # return res
            return self.result
        except requests.RequestException as e:
            logging.error("send_request_json_data_postè¯·æ±‚å‡ºç°å¼‚å¸¸:{0}".format(e))
            # AIGC_HOST= '47.110.156.41'


async def call_http_request(url: str, headers=None, time_out=100.0, **kwargs):
    """
    å¼‚æ­¥è°ƒç”¨HTTPè¯·æ±‚å¹¶è¿”å›JSONå“åº”ï¼Œå¦‚æœå“åº”ä¸æ˜¯JSONæ ¼å¼åˆ™è¿”å›æ–‡æœ¬å†…å®¹
    å›½å†…ï¼Œæ— ä»£ç†ï¼Œå¯èƒ½å†…å®¹æ— è§£æ
    :param url: è¯·æ±‚åœ°å€
    :param headers: è¯·æ±‚å¤´
    :param time_out: è¯·æ±‚è¶…æ—¶æ—¶é—´
    :param kwargs: å…¶ä»–ä¼ é€’ç»™ httpx çš„å‚æ•°
    :return: dict æˆ– None
    """
    async with httpx.AsyncClient() as cx:
        try:
            response = await cx.get(url, headers=headers, timeout=time_out, **kwargs)  # è¯·æ±‚çº§åˆ«çš„è¶…æ—¶ä¼˜å…ˆçº§æ›´é«˜
            response.raise_for_status()
            content_type = response.headers.get("content-type", "")
            if "application/json" in content_type or not content_type:
                try:
                    return response.json()
                except json.JSONDecodeError:
                    pass

            return {'text': response.text}
        except Exception as e:
            print(e)
            return None


def async_to_sync(coro_func, *args, **kwargs):
    try:
        loop = asyncio.get_running_loop()
        if loop.is_running():
            # å¦‚æœå·²åœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œï¼ˆJupyterã€FastAPIï¼‰ï¼Œä¸èƒ½ç›´æ¥ run
            try:
                import nest_asyncio
                nest_asyncio.apply()
                return loop.run_until_complete(coro_func(*args, **kwargs))
            except ImportError:
                task = asyncio.ensure_future(coro_func(*args, **kwargs))  # è¿”å› Taskï¼Œéœ€æ‰‹åŠ¨ await
                while not task.done():
                    time.sleep(0.05)  # é˜»å¡ç›´åˆ°å®Œæˆ
                return task.result()
    except RuntimeError:
        # æ— äº‹ä»¶å¾ªç¯ï¼ˆæ™®é€šè„šæœ¬ï¼‰ï¼Œæœªåœ¨åç¨‹å†…
        return asyncio.run(coro_func(*args, **kwargs))

    # loop å­˜åœ¨ä½†æœªè¿è¡Œï¼ˆæå°‘è§ï¼‰, fallback
    loop = asyncio.get_event_loop()
    return loop.run_until_complete(coro_func(*args, **kwargs))


class OperationHttp:
    _client = None  # httpx.AsyncClient | aiohttp.ClientSession
    _is_httpx = False
    _is_sync = False
    _timeout = 100

    def __init__(self, use_sync=False, time_out: int | float = 100.0):
        try:
            import httpx
            self.__class__._is_httpx = True
        except ImportError:
            try:
                import aiohttp
                self.__class__._is_httpx = False
            except ImportError:
                import requests
                self.__class__._is_sync = True

        self.__class__.is_sync = use_sync
        self.__class__.timeout = time_out

    async def __aenter__(self):
        self.__class__.init_client()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.__class__.close_async()

    def __enter__(self):
        self.__class__.init_client()
        return self

    def __exit__(self, *args):
        self.__class__.close_sync()

    @classmethod
    def init_client(cls):
        if cls._client is None:
            if cls._is_sync:
                if cls._is_httpx:
                    cls._client = httpx.Client(timeout=cls._timeout)  # åº•å±‚ä¸º httpcore
                else:
                    cls._client = requests.Session()  # åŸºäº urllib3
            else:
                if cls._is_httpx:
                    limits = httpx.Limits(max_connections=100, max_keepalive_connections=20)
                    timeout = httpx.Timeout(cls._timeout, read=cls._timeout, write=30.0, connect=5.0)
                    cls._client = httpx.AsyncClient(limits=limits, timeout=timeout)
                else:
                    connector = aiohttp.TCPConnector(limit=100, limit_per_host=20)
                    timeout = aiohttp.ClientTimeout(total=cls._timeout, sock_read=cls._timeout, sock_connect=5.0)
                    cls._client = aiohttp.ClientSession(connector=connector, timeout=timeout)

            # self.semaphore = asyncio.Semaphore(30)

    @classmethod
    async def close_client(cls):
        if cls._is_sync:
            cls.close_sync()
        else:
            await cls.close_async()

    @classmethod
    def close_sync(cls):
        if cls._client:
            cls._client.close()
            cls._client = None

    @classmethod
    async def close_async(cls):
        if cls._client:
            if cls._is_httpx:
                if not cls._client.is_closed:
                    await cls._client.aclose()
            else:
                if not cls._client.closed:
                    await cls._client.close()
            cls._client = None

    @classmethod
    async def get(cls, url, headers=None, **kwargs):
        if cls._is_sync:
            if cls._is_httpx:
                resp = cls._client.get(url, headers=headers, **kwargs)  # params=data
            else:
                resp = cls._client.get(url, headers=headers, timeout=(cls._timeout, cls._timeout), **kwargs)
            resp.raise_for_status()
            return resp.json()
        else:
            if cls._is_httpx:
                resp = await cls._client.get(url, headers=headers, **kwargs)
                resp.raise_for_status()  # å¦‚æœè¯·æ±‚å¤±è´¥ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸
                return resp.json()
            else:
                async with cls._client.get(url, headers=headers or {}, **kwargs) as resp:
                    resp.raise_for_status()
                    return await resp.json()  # await resp.text()

    @classmethod
    async def post(cls, url, json=None, headers=None, **kwargs):
        if cls._is_sync:
            if cls._is_httpx:
                resp = cls._client.post(url, json=json, headers=headers, **kwargs)
            else:
                resp = cls._client.post(url, json=json, headers=headers, timeout=(cls._timeout, cls._timeout), **kwargs)
            resp.raise_for_status()
            return resp.json()
        else:
            if cls._is_httpx:
                resp = await cls._client.post(url, json=json, headers=headers, **kwargs)
                resp.raise_for_status()  # å¦‚æœè¯·æ±‚å¤±è´¥ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸
                return resp.json()
            else:
                async with cls._client.post(url, json=json, headers=headers or {}, **kwargs) as resp:
                    resp.raise_for_status()
                    return await resp.json()

    @classmethod
    def _fallback_post(cls, url, json_payload, headers=None, stream=False):
        try:
            resp = requests.post(url, headers=headers, json=json_payload, timeout=(5, cls._timeout), stream=stream)
            if resp.status_code == 200:
                return resp.json()  # json.loads(resp.content)
            else:
                raise RuntimeError(f"[requests fallback] è¿”å›å¼‚å¸¸: {resp.status_code}, å†…å®¹: {resp.text}")
        except Exception as e:
            print(f"[requests fallback] è¯·æ±‚å¤±è´¥: {e}")
            return None


class Local_Aigc(OperationHttp):
    HOST = 'aigc'  # '47.110.156.41'
    AI_Models = [
        # https://platform.moonshot.cn/console/api-keys
        {'name': 'moonshot', 'type': 'default', 'api_key': '', 'data': None,
         "model": ["moonshot-v1-32k", "moonshot-v1-8k", "moonshot-v1-32k", "moonshot-v1-128k"],
         'url': "https://api.moonshot.cn/v1/chat/completions", 'base_url': "https://api.moonshot.cn/v1"},
        # {'name': 'aigc', 'type': 'default', 'api_key': '', 'data': None,
        #  "model": [],
        #  'url': f"http://{AIGC_HOST}:7000/v1/chat/completions", 'base_url': f"http://{AIGC_HOST}:7000/v1"}
    ]
    _ai_client = None  # local aigc openai client
    _is_openai = False

    def __init__(self, host=AIGC_HOST, use_sync=False, time_out: int | float = 100.0):
        self.__class__.HOST = host
        try:
            from openai import OpenAI, AsyncOpenAI
            self.__class__._is_openai = True
        except ImportError:
            self.__class__._is_openai = False

        super().__init__(use_sync, time_out)

    async def __aenter__(self):
        await self.__class__.init_clients()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.__class__.close_http_client()

    @classmethod
    async def init_clients(cls, api_key=''):
        """è·å–æ¯ä¸ªæ¨¡å‹çš„æ•°æ®"""
        base_url = f"http://{cls.HOST}:7000/v1"
        if cls._ai_client is None:
            if cls._is_openai:
                if cls._is_sync:
                    cls._ai_client = OpenAI(base_url=base_url, timeout=cls._timeout, api_key=api_key or 'empty')
                else:
                    cls._ai_client = AsyncOpenAI(base_url=base_url, timeout=cls._timeout, api_key=api_key or 'empty')

        super().init_client()

        if not any(model['name'] == 'aigc' for model in cls.AI_Models):
            cls.AI_Models.append(
                {'name': 'aigc', 'type': 'default', 'api_key': api_key, 'data': [], "model": [],
                 'url': f"http://{cls.HOST}:7000/v1/chat/completions",
                 'base_url': base_url}
            )

        for model in cls.AI_Models:
            if cls._ai_client is not None and model["name"] == "aigc":  # model['base_url'] == base_url:
                aigc_models = cls._ai_client.models.list() if cls._is_sync else await cls._ai_client.models.list()
                # print(aigc_models)
                models_data = [m.model_dump() for m in aigc_models.data]
            else:
                if model["data"] is None:  # moonshot ç­‰æ²¡æœ‰æ­¤æ¥å£,æ’é™¤
                    continue

                model_name = model.get('name')
                api_key = AI_API_KEYS.get(model_name)
                if api_key:
                    model['api_key'] = api_key

                url = model['base_url'] + '/models'
                try:
                    models = await cls._client.get(url)  # await call_http_request(url)
                    models_data = models['data']
                except Exception as e:
                    models_data = None
                    print(e)

            if models_data:
                model['data'] = models_data
                model["model"] = [m['id'] for m in models_data]
                print(model["model"])

    @classmethod
    async def close_http_client(cls):
        await cls.close_client()
        cls._ai_client = None

    @classmethod
    def close(cls):
        asyncio.run(cls.close_http_client())

    @classmethod
    def find_model(cls, name: str, model_id: int = 0):
        model = next((model for model in cls.AI_Models if model['name'] == name or name in model['model']), None)
        if model:
            model_items = model['model']
            if name in model_items:
                return model, name

            model_id %= len(model_items)
            return model, model_items[model_id]
        return None, None

    @classmethod
    async def get_chat_payload(cls, messages: list[dict] = None, user_request: str = '', user: str = USER_ID,
                               user_name: str = None, system: str = '',
                               temperature: float = 0.4, top_p: float = 0.8, max_tokens: int = 2048,
                               model='moonshot', model_id=0, images: list = None):

        model_info, name = cls.find_model(model, model_id)
        if not name:
            raise ValueError(f"No model found for model={model}, model_id={model_id}")

        if isinstance(messages, list) and messages:
            if system:
                if messages[0].get('role') != 'system':
                    messages.insert(0, {"role": "system", "content": system})
                # messages[-1]['content'] = messages[0]['content'] + '\n' + messages[-1]['content']

            if user_request:
                if messages[-1]["role"] != 'user':
                    messages.append({'role': 'user', 'content': user_request})
                else:
                    pass
                    # if messages[-1]["role"] == 'user':
                    #     messages[-1]['content'] = user_request
            else:
                if messages[-1]["role"] == 'user':
                    user_request = messages[-1]["content"]
        else:
            if messages is None:
                messages = []
            if system:  # system_message
                messages = [{"role": "system", "content": system}]
            messages.append({'role': 'user', 'content': user_request})

        if images:  # å›¾ç‰‡å†…å®¹ç†è§£,(str, list[dict[str, str | Any]]))
            messages[-1]['content'] = [{"type": "text", "text": user_request}]  # text-prompt è¯·è¯¦ç»†æè¿°ä¸€ä¸‹è¿™å‡ å¼ å›¾ç‰‡ã€‚è¿™æ˜¯å“ªé‡Œï¼Ÿ
            messages[-1]['content'] += [{"type": "image_url", "image_url": {"url": image}} for image in images]
        if user_name:
            messages[-1]['name'] = user_name
        # print(messages)
        payload = dict(
            model=name,  # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªæ¨¡å‹
            messages=messages,
            temperature=temperature,
            top_p=top_p,
            # top_k=50,
            max_tokens=max_tokens,
            stream=False,
            # extra_body = {"prefix": "```python\n", "suffix":"åç¼€å†…å®¹"} å¸Œæœ›çš„å‰ç¼€å†…å®¹,åŸºäºç”¨æˆ·æä¾›çš„å‰ç¼€ä¿¡æ¯æ¥è¡¥å…¨å…¶ä½™çš„å†…å®¹
            # response_format={"type": "json_object"}
            # "tools":retrievalã€web_searchã€function
        )
        if user:
            payload['user'] = user
        # payload = {**payload, **kwargs}

        return model_info, payload

    @classmethod
    async def ai_chat(cls, model_info: dict = None, payload: dict = None, get_content: bool = True,
                      fallback: bool = True, **kwargs) -> str | dict:
        """
        æ¨¡æ‹Ÿå‘é€è¯·æ±‚ç»™AIæ¨¡å‹å¹¶æ¥æ”¶å“åº”ã€‚
        :param model_info: æ¨¡å‹ä¿¡æ¯ï¼ˆå¦‚åç§°ã€IDã€é…ç½®ç­‰ï¼‰
        :param payload: è¯·æ±‚çš„è´Ÿè½½ï¼Œé€šå¸¸æ˜¯å¯¹è¯æˆ–æ–‡æœ¬è¾“å…¥
        :param get_content: è¿”å›æ¨¡å‹å“åº”ç±»å‹
        :param fallback: <UNK>
        :param kwargs: å…¶ä»–é¢å¤–å‚æ•°
        :return: è¿”å›æ¨¡å‹çš„å“åº”
        """
        if not (cls._client or cls._ai_client) or not any(model['model'] for model in cls.AI_Models):
            await cls.init_clients()

        if not payload:
            model_info, payload = await cls.get_chat_payload(**kwargs)
        else:
            payload.update(kwargs)  # {**payload, **kwargs}

        if not model_info:
            return f"error occurred: no model,{payload}" if get_content else {"error": "no model"}

        if cls._is_openai and model_info["name"] == "aigc":
            if cls._is_sync:
                completion = cls._ai_client.chat.completions.create(**payload)
            else:
                completion = await cls._ai_client.chat.completions.create(**payload)
            return completion.choices[0].message.content if get_content else completion.model_dump()

        url = model_info['url'] if model_info.get('url') else model_info['base_url'] + '/chat/completions'
        api_key = model_info['api_key']
        headers = {'Content-Type': 'application/json', }
        # payload = payload.copy()
        if api_key:
            if isinstance(api_key, list):
                idx = model_info['model'].index(payload["model"])
                api_key = model_info['api_key'][idx]
            headers["Authorization"] = f'Bearer {api_key}'

        # print(headers, payload, url)

        try:
            data = await cls.post(url, headers=headers, json=payload)

            if get_content:
                result = data.get('choices', [{}])[0].get('message', {}).get('content')
                if result:
                    return result
                # print(response.text)
            return data

        except Exception as e:
            print(f"HTTP error occurred: {e}", model_info, url)  # can't start new thread
            if fallback:
                data = cls._fallback_post(url, payload, headers, stream=False)
                if get_content:
                    result = data.get('choices', [{}])[0].get('message', {}).get('content')
                    if result:
                        return result
                    # print(response.text)
                return data

            return f"HTTP error occurred: {e}" if get_content else {
                "error": str(e),
                "status": "failed"
            }

    @classmethod
    async def chat_run(cls, rows: list, system: str, model="qwen:qwen3-32b", max_concurrent: int = 100,
                       max_tries: int = 3, **kwargs) -> list:
        """
        å¼‚æ­¥å¹¶å‘åˆ†ç±»ä»»åŠ¡æ‰§è¡Œå™¨ã€‚

        æ¯æ¡ row å¯ä»¥æ˜¯ dictï¼ˆè‡ªåŠ¨æ ¼å¼åŒ–ä¸º key,value æ‹¼æ¥ï¼‰æˆ– strï¼ˆç›´æ¥ä½œä¸º promptï¼‰ï¼Œ
        system prompt é€šç”¨ä¼ å…¥ï¼Œé€‚ç”¨äº prompt å·²åœ¨å¤–éƒ¨æ„é€ çš„æƒ…å½¢ã€‚
        """

        def format_user_request(row):
            if isinstance(row, dict):
                return '|'.join(
                    f"{k}:{v.strip() if isinstance(v, str) else v}" for k, v in row.items() if v is not None)
            return str(row)

        async def limited_run(semaphore, row):
            async with semaphore:
                for attempt in range(1, max_tries + 1):
                    result = await cls.ai_chat(model=model, system=system, user_request=format_user_request(row),
                                               **kwargs)
                    if isinstance(result, dict):
                        content = result.get('choices', [{}])[0].get('message', {}).get('content')
                    else:
                        content = str(result) if result is not None else ''

                    if 'Error code: 429' in content or 'error' in content.lower():
                        print(f"[é‡è¯•] ç¬¬ {attempt} æ¬¡å¤±è´¥ï¼Œå†…å®¹: {content}")
                        await asyncio.sleep(2 * attempt)
                        continue

                    return result

                print("error: Failed after tries", f"row: {row}")
                return result

        semaphore = asyncio.Semaphore(max_concurrent)
        tasks = [limited_run(semaphore, row) for row in rows]
        return await asyncio.gather(*tasks)

    @classmethod
    async def model_test(cls, user_request: str, system: str, model_names: list = None, max_concurrent: int = 50,
                         max_tries: int = 1, **kwargs) -> list:

        async def limited_run(semaphore, model):
            async with semaphore:
                for attempt in range(1, max_tries + 1):
                    result = await cls.ai_chat(model=model, system=system, user_request=user_request,
                                               **kwargs)
                    if isinstance(result, dict):
                        content = result.get('choices', [{}])[0].get('message', {}).get('content')
                    else:
                        content = str(result) if result is not None else ''
                        result = {'model': model, 'content': content}

                    if 'Error code: 429' in content or 'error' in content.lower():
                        print(f"[é‡è¯•] ç¬¬ {attempt} æ¬¡å¤±è´¥ï¼Œå†…å®¹: {content}")
                        await asyncio.sleep(2 * attempt)
                        continue

                    return result

                print("error: Failed after tries", f"model: {model}")
                return result

        if not model_names:
            for model in cls.AI_Models:
                if model['name'] == "aigc":
                    model_names = model['model']

        semaphore = asyncio.Semaphore(max_concurrent)
        tasks = [limited_run(semaphore, model) for model in model_names]
        return await asyncio.gather(*tasks)

    @classmethod
    def chat(cls, **kwargs) -> str | dict:
        return async_to_sync(cls.ai_chat, **kwargs)


def request_aigc(history, question, system, model_name, agent='0', stream=False, host=AIGC_HOST, get_content=False,
                 time_out: int | float = 100, **kwargs) -> str | dict:
    headers = {'accept': 'application/json', 'Content-Type': 'application/json'}
    url = f"http://{host}:7000/message/"
    # url = 'http://47.110.156.41:7000/message'  # å¤–ç½‘
    body = {
        "agent": agent,
        "extract": "json",
        "messages": history,
        "keywords": [],
        "tools": [],

        "model_id": 0,
        "model_name": model_name,
        "prompt": system,
        "question": question,
        "stream": stream,
        "max_tokens": 1024,
        "temperature": 0.4,
        "top_p": 0.8,

        "name": None,
        "user": USER_ID,
        "robot_id": None,
        "request_id": None,

        "filter_time": 0,
        "filter_limit": -500,
        "use_hist": False,
    }

    body.update(kwargs)
    try:
        response = requests.post(url, headers=headers, json=body, timeout=(10, time_out), stream=stream)
        data = response.json()

    except Exception as e:
        print(body)
        return f"HTTP error occurred: {e}" if get_content else {"error": str(e), "status": "failed"}

    if get_content:
        return data.get('transform') or data.get('answer') or data
    return data


async def request_aigc_sterm(history, question, system, model_name, assistant_response=None, host=AIGC_HOST,
                             **kwargs):
    url = f"http://{host}:7000/message"
    headers = {'accept': 'application/json', 'Content-Type': 'application/json'}

    payload = {
        "agent": "0",
        "extract": "json",
        "filter_time": 0,
        "max_tokens": 1024,
        "messages": history,
        "model_id": 0,
        "keywords": [],
        "model_name": model_name,
        "prompt": system,
        "question": question,
        "stream": True,
        "temperature": 0.4,
        "top_p": 0.8,
        "use_hist": False,
        "user": USER_ID,
        "robot_id": None,
        "request_id": None,
    }

    payload.update(kwargs)
    async with httpx.AsyncClient() as client:
        async with client.stream('POST', url, json=payload, headers=headers) as response:
            async for chunk in response.iter_lines(decode_unicode=True):  # .aiter_text()
                if not chunk:
                    continue
                if chunk.startswith("data: "):
                    if assistant_response is None:
                        yield f"{chunk}\n\n"
                    else:
                        line_data = chunk.lstrip("data: ")
                        if line_data == "[DONE]":
                            break
                        try:
                            parsed_content = json.loads(line_data)
                            yield f'data: {json.dumps(parsed_content, ensure_ascii=False)}\n\n'
                            # if isinstance(parsed_content, dict) and parsed_content.get("content", ""):
                            #     if parsed_content.get('role') == 'assistant':
                            #         assistant_response = [parsed_content.get('content')]
                        except json.JSONDecodeError:
                            yield f'data: {line_data}\n\n'
                            assistant_response.append(line_data)

                await asyncio.sleep(0.01)


async def request_aigc_async(history: list, question, system, model_name, agent='0', stream=False, host=AIGC_HOST,
                             get_content=False, time_out: int | float = 100, **kwargs) -> str | dict:
    headers = {'accept': 'application/json', 'Content-Type': 'application/json'}
    url = f"http://{host}:7000/message/"
    # url = 'http://47.110.156.41:7000/message'  # å¤–ç½‘
    payload = {
        "agent": agent,
        "extract": "json",
        "messages": history,
        "keywords": [],
        "tools": [],

        "model_id": 0,
        "model_name": model_name,
        "prompt": system,
        "question": question,
        "stream": stream,
        "max_tokens": 1024,
        "temperature": 0.4,
        "top_p": 0.8,

        "name": None,
        "uuid": None,
        "user": USER_ID,
        "robot_id": None,

        "filter_time": 0,
        "filter_limit": -500,
        "use_hist": False,
    }

    payload.update(kwargs)  # åªæ›´æ–° kwargs é‡Œé¢çš„ key

    def extract(data):
        return data.get('transform') or data.get('answer') or data if get_content else data

    # print(headers, payload, url)
    limits = httpx.Limits(max_connections=100, max_keepalive_connections=50)
    timeout = httpx.Timeout(time_out, read=time_out, write=30.0, connect=5.0)
    try:
        async with httpx.AsyncClient(limits=limits, timeout=timeout) as cx:
            response = await cx.post(url, headers=headers, json=payload)
            response.raise_for_status()  # å¦‚æœè¯·æ±‚å¤±è´¥ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸
            data = response.json()
            return extract(data)

    except (RuntimeError, httpx.HTTPStatusError, httpx.RequestError) as e:
        print(f"[httpx] è¯·æ±‚å¤±è´¥: {e}ï¼Œå°è¯• fallback requests...")
        response = RunMethod().post_main(url, json.dumps(payload), headers=headers, timeout=(30, time_out),
                                         stream=stream)

        if response.status_code == 200:
            data = json.loads(response.content)  # response.content.decode('utf-8')
            return extract(data)
        else:
            raise RuntimeError(
                f"[requests fallback] è¿”å›ä¸ºç©ºæˆ–çŠ¶æ€ç å¼‚å¸¸: {response.status_code}, å†…å®¹: {response.text}")

    except Exception as e:
        print(f"[requests] fallback error: {e}ï¼Œå°è¯•æœ€ç»ˆ fallback å‡½æ•°...")
        # fallback to sync version:can't start new thread

    return request_aigc(history, question, system, model_name, agent, stream, host, get_content, time_out, **kwargs)


async def aigc_completion_wechat(question='', system='', name=None, robot_id='æœºå™¨äººå°D',
                                 model_id='qwen', agent='0', filter_time=0, time_out=100, **kwargs):
    payload = {
        "history": [],
        "question": question,
        "system": system,
        "model_name": model_id,
        "agent": agent,
        "extract": "wechat",
        "stream": False,
        "temperature": 0.4,
        "max_tokens": 4096,
        "robot_id": robot_id,
        "name": name,
        "filter_time": filter_time,
        "filter_limit": -100,
        "use_hist": True,
    }

    kwargs.pop("get_content", None)
    payload.update(kwargs)

    return await request_aigc_async(**payload, get_content=True, time_out=time_out)


def aigc_message_callback(question, system, history: list[dict] = None, keywords: list = None,
                          callback_data: str | dict = None, model_id='moonshot', agent='0', host=AIGC_HOST,
                          time_out: int | float = 100, **kwargs) -> dict:
    headers = {'accept': 'application/json', 'Content-Type': 'application/json'}
    url = f"http://{host}:7000/submit_messages"
    param = {
        "stream": False,
        "temperature": 0.6,
        "top_p": 0.7,
        "max_tokens": 4096,
        "prompt": system,
        "question": question,
        "keywords": keywords,
        "tools": [],
        'images': [],
        "callback": {},
        "agent": agent,
        "extract": "json",
        "model_name": model_id,
        "model_id": 0,
    }
    body = {
        "uuid": None,
        "name": None,
        "robot_id": None,
        "user": USER_ID,
        "use_hist": False,
        "filter_limit": -500,
        "filter_time": 0.0,
        "messages": history,  # not user_messages and use_hist get message_records from db, else use chat_history
        "params": [param]
    }
    if callback_data:
        if isinstance(callback_data, str):
            param["callback"]["url"] = callback_data
        elif isinstance(callback_data, dict):
            param["callback"] = callback_data

    for k, v in kwargs.items():
        if k in param:
            param[k] = v
        else:
            body[k] = v  # é params é‡Œçš„æ”¾é¡¶å±‚

    body["params"][0] = param

    try:
        response = RunMethod().post_main(url, json.dumps(body), headers=headers, timeout=(30, time_out))
        data = json.loads(response.content)  # response.content.decode('utf-8')

    except Exception as e:
        print(body)
        raise RuntimeError(f"[requests] è¿”å›ä¸ºç©ºæˆ–çŠ¶æ€ç å¼‚å¸¸: {e}")

    return data


def aigc_message_wechat(question, system, name=None, history: list[dict] = None, keywords: list = None,
                        model_id='moonshot', agent='0', host=AIGC_HOST, time_out: int | float = 100, **kwargs) -> dict:
    headers = {'accept': 'application/json', 'Content-Type': 'application/json'}
    url = f"http://{host}:7000/submit_messages"

    body = {
        "uuid": None,
        "name": name,
        "robot_id": None,
        "user": USER_ID,
        "use_hist": True,
        "filter_limit": -500,
        "filter_time": 0.0,
        "messages": history,  # not user_messages and use_hist get message_records from db, else use chat_history
        "params": [{
            "stream": False,
            "temperature": 0.8,
            "top_p": 0.8,
            "max_tokens": 4096,
            "prompt": system,
            "question": question,
            "keywords": keywords,
            "tools": [],
            'images': [],
            "callback": {},
            "agent": agent,
            "extract": "wechat",
            "model_name": model_id,
            "model_id": 0,
            # "score_threshold": 0.0,
            # "top_n": 10,
        }]
    }
    for k, v in kwargs.items():
        if k in body["params"][0]:
            body["params"][0][k] = v
        else:
            body[k] = v  # é params é‡Œçš„æ”¾é¡¶å±‚

    try:
        response = RunMethod().post_main(url, json.dumps(body), headers=headers, timeout=(30, time_out))
        data = json.loads(response.content)  # response.content.decode('utf-8')

    except Exception as e:
        print(body)
        raise RuntimeError(f"[requests] è¿”å›ä¸ºç©ºæˆ–çŠ¶æ€ç å¼‚å¸¸: {e}")

    return data


def aigc_chat(user_request: str, system: str, model="moonshot:moonshot-v1-8k", get_content: bool = True,
              host=AIGC_HOST, time_out: int | float = 100, **kwargs):
    history = [
        {"role": "system", "content": system or "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·è§£å†³é—®é¢˜"},
        {"role": "user", "content": user_request}
    ]
    payload = dict(
        model=model,
        messages=history,
        temperature=0.3,
        top_p=0.8,
        # top_k=50,
        max_tokens=1024,
        stream=False,
    )
    payload.update(kwargs)

    headers = {'Content-Type': 'application/json', }
    url = f"http://{host}:7000/v1/chat/completions"
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=(10, time_out))
        data = response.json()
        return data.get('choices', [{}])[0].get('message', {}).get('content') if get_content else data
    except Exception as e:
        print(payload)
        return f"HTTP error occurred: {e}" if get_content else {"error": str(e), "status": "failed"}


async def ai_chat_async(messages: list[dict] = None, user_request: str = '', user: str = USER_ID, name: str = None,
                        system: str = '', temperature: float = 0.4, top_p: float = 0.8, max_tokens: int = 1024,
                        tools: list[dict] = None, _client=None, model='moonshot', host=AIGC_HOST,
                        get_content: bool = True, api_key: str = None,
                        time_out: int | float = 100, **kwargs) -> str | dict:
    if not messages:
        messages = []
    if system and (not messages or messages[0].get("role") != "system"):
        messages.insert(0, {"role": "system", "content": system})
    if user_request and (not messages or messages[-1].get("role") != "user"):
        messages.append({"role": "user", "content": user_request, "name": name})

    payload = dict(
        model=model,  # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªæ¨¡å‹
        messages=messages,
        temperature=temperature,
        top_p=top_p,
        # top_k=50,
        max_tokens=max_tokens,
        stream=False,
        # extra_body = {"prefix": "```python\n", "suffix":"åç¼€å†…å®¹"} å¸Œæœ›çš„å‰ç¼€å†…å®¹,åŸºäºç”¨æˆ·æä¾›çš„å‰ç¼€ä¿¡æ¯æ¥è¡¥å…¨å…¶ä½™çš„å†…å®¹
        # response_format={"type": "json_object"}
        # "tools":retrievalã€web_searchã€function
    )
    if user:
        payload['user'] = user
    if tools:
        payload['tools'] = tools  # retrievalã€web_searchã€function\map_search\intent_search\baidu_search
    payload.update(kwargs)

    if _client:
        completion = _client.chat.completions.create(**payload)
        return completion.choices[0].message.content if get_content else completion.model_dump()

    url = f"http://{host}:7000/v1/chat/completions"
    headers = {'Content-Type': 'application/json', }
    if api_key:
        headers["Authorization"] = f'Bearer {api_key}'

    # print(headers, payload, url)
    limits = httpx.Limits(max_connections=100, max_keepalive_connections=50)
    timeout = httpx.Timeout(time_out, read=time_out, write=30.0, connect=5.0)
    try:
        async with httpx.AsyncClient(limits=limits, timeout=timeout) as cx:
            response = await cx.post(url, headers=headers, json=payload)
            response.raise_for_status()  # å¦‚æœè¯·æ±‚å¤±è´¥ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸
            data = response.json()

            if get_content:
                result = data.get('choices', [{}])[0].get('message', {}).get('content')
                if result:
                    return result
                print(response.text)
            return data

    except (RuntimeError, httpx.HTTPStatusError, httpx.RequestError) as e:
        print(f"[httpx] è¯·æ±‚å¤±è´¥: {e}:{host},å°è¯• fallback requests...")
        response = RunMethod().post_main(url, json.dumps(payload), headers=headers, timeout=(30, time_out))
        if response.status_code == 200:
            data = json.loads(response.content)  # response.content.decode('utf-8')
            return data.get('choices', [{}])[0].get('message', {}).get('content') if get_content else data
        else:
            raise RuntimeError(
                f"[requests fallback] è¿”å›ä¸ºç©ºæˆ–çŠ¶æ€ç å¼‚å¸¸: {response.status_code}, å†…å®¹: {response.text}")

    except Exception as e:
        print(f"[requests] fallback error: {e}ï¼Œå°è¯•æœ€ç»ˆ fallback å‡½æ•°...")

    return aigc_chat(user_request, system, model, get_content, host, time_out, **kwargs)


async def request_llm(question, system, keywords=[], model_name='qwen', agent='0', host=AIGC_HOST, **kwargs):
    headers = {'accept': 'application/json', 'Content-Type': 'application/json'}
    url = f"http://{host}:7000/llm"
    body = {
        'prompt': system,
        "question": question,
        "agent": agent,
        "suffix": "",
        "stream": False,
        "temperature": 0.4,
        "top_p": 0.8,
        "model_name": model_name,
        "model_id": 0,
        "extract": "json",
        "max_tokens": 4096,
        "keywords": keywords,
        "tools": [],
    }

    body.update(kwargs)
    try:
        async with httpx.AsyncClient(timeout=60) as client:
            response = await client.post(url, json=body, headers=headers)
            response.raise_for_status()
            return response.json()
    except (RuntimeError, httpx.HTTPStatusError, httpx.RequestError) as e:
        response = RunMethod().post_main(url, json.dumps(body), headers=headers, timeout=(10, 60))
        return json.loads(response.content)
    except Exception as e:
        print(e)


async def request_classify(question, intent_keywords: dict[str, list] = None, last_intents=None,
                           host=AIGC_HOST, **kwargs):
    headers = {'accept': 'application/json', 'Content-Type': 'application/json'}
    url = f"http://{host}:7000/classify"
    body = {
        'query': question,
        "class_terms": intent_keywords,
        "class_default": last_intents,
        'emb_model': 'text-embedding-v2',
        "rerank_model": "BAAI/bge-reranker-v2-m3",
        'cutoff': 0.85,
    }

    body.update(kwargs)
    timeout = httpx.Timeout(60, read=60.0, write=30.0, connect=5.0)
    try:
        async with httpx.AsyncClient(timeout=timeout) as cx:
            response = await cx.post(url, json=body, headers=headers)
            response.raise_for_status()
            return response.json()
    except (RuntimeError, httpx.HTTPStatusError, httpx.RequestError) as e:
        response = RunMethod().post_main(url, json.dumps(body), headers=headers, timeout=(10, 60))
        return json.loads(response.content)
    except Exception as e:
        print(e)


async def request_tools(question, tools=[], model_name='qwen-turbo', host=AIGC_HOST, **kwargs):
    headers = {'accept': 'application/json', 'Content-Type': 'application/json'}
    url = f"http://{host}:7000/tools"
    body = {
        "messages": [
            # {
            #     "content": question,
            #     "role": "user"
            # }
        ],
        "tools": tools,
        "model_id": 0,
        "model_name": model_name,
        "prompt": question,
        "temperature": 0.01,
        "top_p": 0.95
    }

    body.update(kwargs)
    timeout = httpx.Timeout(60, read=60.0, write=30.0, connect=5.0)
    try:
        async with httpx.AsyncClient(timeout=timeout) as client:
            response = await client.post(url, json=body, headers=headers)
            response.raise_for_status()
            return response.json()
    except (RuntimeError, httpx.HTTPStatusError, httpx.RequestError) as e:
        response = RunMethod().post_main(url, json.dumps(body), headers=headers, timeout=(10, 60))
        return json.loads(response.content)
    except Exception as e:
        print(e)


def generate_embeddings(sentences: list, model_name='qwen', host=AIGC_HOST):
    url = f'http://{host}:7000/embeddings/'
    payload = {'texts': sentences, 'model_name': model_name, 'model_id': 0}
    response = requests.post(url, json=payload)
    if response.status_code == 200:
        return response.json()['embedding']

    return []


async def request_knowledge(question, model_name='BAAI/bge-reranker-v2-m3', version=0, host=AIGC_HOST, **kwargs):
    headers = {'accept': 'application/json', 'Content-Type': 'application/json'}
    url = f"http://{host}:7000/knowledge/"
    body = {
        "text": question,
        "rerank_model": model_name,
        "version": version,
    }

    body.update(kwargs)
    timeout = httpx.Timeout(60, read=60.0, write=30.0, connect=5.0)
    try:
        async with httpx.AsyncClient(timeout=timeout) as client:
            response = await client.get(url, params=body, headers=headers)
            response.raise_for_status()
            return response.json()
    except (RuntimeError, httpx.HTTPStatusError, httpx.RequestError) as e:
        response = RunMethod().get_main(url, json.dumps(body), headers=headers, timeout=(10, 60))
        return json.loads(response.content)
    except Exception as e:
        print(e)


def random_responses():
    import random
    responses = ['æœºå™¨äººæš‚æ—¶æ²¡æœ‰å›å¤å“¦~',
                 "å¯¹ä¸èµ·ï¼Œæˆ‘ä¸æ˜ç™½",
                 "æˆ‘æ­£åœ¨å°è¯•",
                 "æˆ‘ä¸èƒ½è¿™ä¹ˆåš",
                 "è¯·å†é‡å¤ä¸€æ¬¡",
                 "æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—?",
                 "è¯·é—®å…·ä½“é—®é¢˜æ˜¯ä»€ä¹ˆ?",
                 "ä½ å¥½ï¼Œæˆ‘ç°åœ¨æ­£åœ¨çº¿ä¸Š"
                 # "å½“ç„¶å¯ä»¥",
                 # "æˆ‘èƒ½åšåˆ°",
                 ]
    weights = [0.25, 0.15, 0.1, 0.05, 0.07, 0.09, 0.14, 0.15]
    # æ ¹æ®æƒé‡é€‰æ‹©å“åº”
    return random.choices(responses, weights=weights, k=1)[0]


def format_for_wechat(text):
    formatted_text = text
    formatted_text = re.sub(r'\*\*(.*?)\*\*', r'âœ¦\1âœ¦', formatted_text)  # **ç²—ä½“** è½¬æ¢ä¸º âœ¦ç²—ä½“âœ¦æ ·å¼
    formatted_text = re.sub(r'!!(.*?)!!', r'â—\1â—', formatted_text)  # !!é«˜äº®!! è½¬æ¢ä¸º â—ç¬¦å·åŒ…å›´
    # formatted_text = re.sub(r'__(.*?)__', r'â€»\1â€»', formatted_text)  # __æ–œä½“__ è½¬æ¢ä¸ºæ˜Ÿå·åŒ…å›´çš„æ ·å¼
    formatted_text = re.sub(r'~~(.*?)~~', r'_\1_', formatted_text)  # ~~ä¸‹åˆ’çº¿~~ è½¬æ¢ä¸ºä¸‹åˆ’çº¿åŒ…å›´
    formatted_text = re.sub(r'\^\^(.*?)\^\^', r'||\1||', formatted_text)  # ^^é‡è¦^^ è½¬æ¢ä¸º ||é‡è¦|| åŒ…å›´
    formatted_text = re.sub(r'######\s+(.*?)(\n|$)', r'[\1]\n', formatted_text)  # ###### å…­çº§æ ‡é¢˜
    formatted_text = re.sub(r'#####\s+(.*?)(\n|$)', r'ã€Š\1ã€‹\n', formatted_text)  # ##### äº”çº§æ ‡é¢˜
    formatted_text = re.sub(r'####\s+(.*?)(\n|$)', r'ã€\1ã€‘\n', formatted_text)  # #### æ ‡é¢˜è½¬æ¢
    formatted_text = re.sub(r'###\s+(.*?)(\n|$)', r'â€” \1 â€”\n', formatted_text)  # ### ä¸‰çº§æ ‡é¢˜
    formatted_text = re.sub(r'##\s+(.*?)(\n|$)', r'â€”â€” \1 â€”â€”\n', formatted_text)  # ## äºŒçº§æ ‡é¢˜
    formatted_text = re.sub(r'#\s+(.*?)(\n|$)', r'â€» \1 â€»\n', formatted_text)  # # ä¸€çº§æ ‡é¢˜
    # formatted_text = re.sub(r'```([^`]+)```',
    #                         lambda m: '\n'.join([f'ï½œ {line}' for line in m.group(1).splitlines()]) + '\n',
    #                         formatted_text)
    # formatted_text = re.sub(r'`([^`]+)`', r'ã€Œ\1ã€', formatted_text)  # `ä»£ç ` è½¬æ¢ä¸ºã€Œä»£ç ã€æ ·å¼
    # formatted_text = re.sub(r'>\s?(.*)', r'ğŸ’¬ \1', formatted_text)  # > å¼•ç”¨æ–‡æœ¬ï¼Œè½¬æ¢ä¸ºèŠå¤©ç¬¦å·åŒ…å›´
    # formatted_text = re.sub(r'^\s*[-*+]\s+', 'â€¢ ', formatted_text, flags=re.MULTILINE)  # æ— åºåˆ—è¡¨é¡¹
    # formatted_text = re.sub(r'^\s*\d+\.\s+',f"{next(ordinal_iter)} ", formatted_text, flags=re.MULTILINE)  # æœ‰åºåˆ—è¡¨é¡¹
    formatted_text = re.sub(r'\n{2,}', '\n\n', formatted_text)  # è½¬æ¢æ¢è¡Œä»¥é¿å…å¤šä½™ç©ºè¡Œ

    return formatted_text.strip()


def generate_hash_key(*args, **kwargs):
    """
    æ ¹æ®ä»»æ„è¾“å…¥å‚æ•°ç”Ÿæˆå”¯ä¸€çš„ç¼“å­˜é”®ã€‚
    :param args: ä»»æ„ä½ç½®å‚æ•°ï¼ˆå¦‚æ¨¡å‹åç§°ã€æ¨¡å‹ ID ç­‰ï¼‰
    :param kwargs: ä»»æ„å…³é”®å­—å‚æ•°ï¼ˆå¦‚å…¶ä»–æè¿°æ€§ä¿¡æ¯ï¼‰
    :return: å“ˆå¸Œé”®
    """
    # å°†ä½ç½®å‚æ•°å’Œå…³é”®å­—å‚æ•°ç»Ÿä¸€æ‹¼æ¥æˆä¸€ä¸ªå­—ç¬¦ä¸²
    inputs = []
    for arg in args:
        if isinstance(arg, list):
            inputs.extend(map(str, arg))  # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œé€ä¸ªè½¬æ¢ä¸ºå­—ç¬¦ä¸²
        else:
            inputs.append(str(arg))

    for key, value in kwargs.items():
        inputs.append(f"{key}:{value}")  # æ ¼å¼åŒ–å…³é”®å­—å‚æ•°ä¸º key:value

    joined_key = "|".join(inputs)  # [:1000]
    # è¿”å› MD5 å“ˆå¸Œ
    return hashlib.md5(joined_key.encode()).hexdigest()


def map_fields(data: dict, mapping: dict) -> dict:
    def translate_key(prefix, key):
        full_key = f"{prefix}.{key}" if prefix else key
        return mapping.get(full_key, mapping.get(key, key))

    def recursive_map(obj, prefix=""):
        if isinstance(obj, dict):
            return {translate_key(prefix, k): recursive_map(v, f"{prefix}.{k}" if prefix else k)
                    for k, v in obj.items()}
        elif isinstance(obj, list):
            return [recursive_map(item, prefix) for item in obj]
        else:
            return obj

    return recursive_map(data)


if __name__ == '__main__':
    import nest_asyncio

    nest_asyncio.apply()
    AIGC_HOST = '47.110.156.41'


    async def main():
        global AIGC_HOST

        # await Local_Aigc.init_clients()
        async with Local_Aigc(host=AIGC_HOST) as client:
            print(await client.ai_chat(model="qwen:qwq-plus", user_request="ä½ å¥½"))

        config = Local_Aigc(host=AIGC_HOST, use_sync=False)
        try:
            res = await Local_Aigc.ai_chat(model='moonshot:moonshot-v1-8k', user_request='ä½ å¥½')
            print(res)
            print(await Local_Aigc.ai_chat(model='qwen:qwq-plus', user_request='ä½ å¥½'))
            print(Local_Aigc.AI_Models)
            res = await ai_chat_async(model='qwen:qwen3-32b', user_request='ä½ å¥½', host=AIGC_HOST)
            print(res)
        finally:
            await Local_Aigc.close_http_client()


    asyncio.run(main())

    Local_Aigc(host=AIGC_HOST, time_out=300, use_sync=True)

    print(Local_Aigc.chat(model='qwen:qwq-plus', user_request='ä½ å¥½å•Šï¼Œè°¢è°¢ä½ '))

    Local_Aigc.close()

    with Local_Aigc(host=AIGC_HOST) as cx:
        print(cx.chat(model='qwen:qwq-plus', user_request='ä½ å¥½å•Š'))
