import re, json, io, os
import inspect
from pathlib import Path
from contextlib import redirect_stdout
import xml.etree.ElementTree as ET
from difflib import get_close_matches, SequenceMatcher
from collections import OrderedDict, Counter
import math
import jieba
from pypinyin import lazy_pinyin
from langdetect import detect, detect_langs
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta


class LRUCache:
    def __init__(self, capacity: int):
        self.stack = OrderedDict()
        self.capacity = capacity

    def get(self, key):
        if key in self.stack:
            self.stack.move_to_end(key)
            return self.stack[key]
        else:
            return None

    def put(self, key, value) -> None:
        if key in self.stack:
            self.stack[key] = value
            self.stack.move_to_end(key)
        else:
            self.stack[key] = value
        if len(self.stack) > self.capacity:
            self.stack.popitem(last=False)

    def change_capacity(self, capacity):
        self.capacity = capacity
        for i in range(len(self.stack) - capacity):
            self.stack.popitem(last=False)

    def delete(self, key):
        if key in self.stack:
            del self.stack[key]

    def keys(self):
        return self.stack.keys()

    def __len__(self):
        return len(self.stack)

    def __contains__(self, key):
        return key in self.stack


def get_function_parameters(func):
    signature = inspect.signature(func)
    parameters = signature.parameters
    return [param for param in parameters]


def get_function_string(func):
    try:
        function_code = inspect.getsource(func)
        return function_code
    except Exception as e:
        return f"{e}"


# é€’å½’åœ°å°†å­—å…¸ä¸­çš„æ‰€æœ‰é”®åè½¬æ¢ä¸ºé¦–å­—æ¯å¤§å†™çš„é©¼å³°å‘½å
def convert_keys_to_pascal_case(d):
    if isinstance(d, dict):
        new_dict = {}
        for k, v in d.items():
            new_key = ''.join(x.title() for x in k.split('_'))
            new_dict[new_key] = convert_keys_to_pascal_case(v)
        return new_dict
    elif isinstance(d, list):
        return [convert_keys_to_pascal_case(item) for item in d]
    else:
        return d


def extract_json_from_string(input_str):
    match = re.search(r'\{.*}', input_str, re.DOTALL)
    if match:
        json_str = match.group(0)
        try:
            return json.loads(json_str)
        except json.JSONDecodeError as e:
            print(f"Error decoding JSON: {e}")
    return None


def extract_method_calls(text):
    # åŒ¹é…æ–¹æ³•è°ƒç”¨ï¼ˆæ–¹æ³•å+æ‹¬å·å†…å®¹ï¼‰
    pattern = r"\b[a-zA-Z_][a-zA-Z0-9_]*\b"
    matches = re.findall(pattern, text)
    # æ£€æŸ¥åŒ¹é…é¡¹ï¼Œè¿”å›æœ€åä¸€ä¸ªæ–¹æ³•å
    if matches:
        return matches[-1]
    return None


def execute_code_blocks(text):
    code_blocks = extract_python_code(text)
    results = []
    global_namespace = globals()  # å¼•ç”¨å…¨å±€å‘½åç©ºé—´
    for code in code_blocks:
        local_namespace = {}  # ç”¨äºå­˜å‚¨ä»£ç çš„å±€éƒ¨å˜é‡
        captured_output = io.StringIO()  # ç”¨äºæ•è· `print` è¾“å‡º
        try:
            with redirect_stdout(captured_output):  # é‡å®šå‘ `print` è¾“å‡º
                exec(code, global_namespace, local_namespace)
                # exec(code, globals=None, locals=None)ç”¨äºåŠ¨æ€æ‰§è¡Œè¾ƒå¤æ‚çš„ä»£ç å—,ä¸è¿”å›ç»“æœ,éœ€è¦é€šè¿‡å…¨å±€æˆ–å±€éƒ¨å˜é‡è·å–ç»“æœ
            output = captured_output.getvalue()  # è·å– `print` çš„å†…å®¹
            results.append({
                "output": output.strip(),
                "namespace": local_namespace,
                "error": None
            })
        except Exception as e:
            results.append({
                "output": captured_output.getvalue().strip(),
                "namespace": local_namespace,
                "error": f"Error executing code block: {e}"
            })
        finally:
            captured_output.close()

    return results


# è°ƒæ•´ç¼©è¿›,ä¿®å¤ä»£ç ç¼©è¿›ï¼Œç¡®ä¿æœ€å°çš„ç¼©è¿›è¢«ç§»é™¤ï¼Œä»¥é¿å…ç¼©è¿›é”™è¯¯
def fix_indentation(code):
    lines = code.splitlines()

    min_indent = min(len(line) - len(line.lstrip()) for line in lines if line.strip())
    fixed_lines = [line[min_indent:] if len(line) >= min_indent else line for line in lines]
    return "\n".join(fixed_lines)


def extract_python_code(text):
    code_blocks = re.findall(r'```(?:python)?(.*?)```', text, re.DOTALL)
    if not code_blocks:
        code_blocks = re.findall(r'((?: {4}.*\n)+)', text)

    return [fix_indentation(block) for block in code_blocks]  # [block.strip()]


def extract_sql_code(text):
    sql_blocks = re.findall(r'```(?:sql)?(.*?)```', text, re.DOTALL)
    if not sql_blocks:
        sql_blocks = re.findall(r'((?:SELECT|INSERT|UPDATE|DELETE).*?;)', text, re.DOTALL)
    return [block.strip() for block in sql_blocks]


def extract_html_code(text):
    html_blocks = re.findall(r'```(?:html)?(.*?)```', text, re.DOTALL)
    if not html_blocks:
        html_blocks = re.findall(r'(<html.*?</html>)', text, re.DOTALL | re.IGNORECASE)
    return [block.strip() for block in html_blocks]


def extract_cpp_code(text):
    cpp_blocks = re.findall(r'```(?:cpp|c\+\+)?(.*?)```', text, re.DOTALL)
    return [block.strip() for block in cpp_blocks]


def extract_java_code(text):
    java_blocks = re.findall(r'```(?:java)?(.*?)```', text, re.DOTALL)
    return [block.strip() for block in java_blocks]


def extract_bash_code(text):
    bash_blocks = re.findall(r'```(?:bash|sh)?(.*?)```', text, re.DOTALL)
    return [block.strip() for block in bash_blocks]


def extract_table_data(text):
    table_blocks = re.findall(r'```(?:table)?(.*?)```', text, re.DOTALL)
    if not table_blocks:
        table_blocks = re.findall(r'((?:\|.*?\|)+)', text)  # ç®€å•åŒ¹é… Markdown è¡¨æ ¼ï¼Œå¦‚ | A | B |
    return [block.strip() for block in table_blocks]


def extract_list_data(text):
    list_blocks = re.findall(r'```(?:list)?(.*?)```', text, re.DOTALL)
    if not list_blocks:
        list_blocks = re.findall(r'(\n\s*[-*].*?(\n\s{2,}.*?)*\n)', text)  # çº¯æ–‡æœ¬åˆ—è¡¨
    return [block.strip() for block in list_blocks]


def extract_json_data(text):
    # æå– JSON æ ¼å¼çš„ä»£ç å—
    json_blocks = re.findall(r'```(?:json)?(.*?)```', text, re.DOTALL)
    return [block.strip() for block in json_blocks]


def extract_code_blocks(text, lag=''):
    funcs = {
        "sql": extract_sql_code,
        "html": extract_html_code,
        "python": extract_python_code,
        "cpp": extract_cpp_code,
        "java": extract_java_code,
        "bash": extract_bash_code,

        "table": extract_table_data,
        "list": extract_list_data,
        "json": extract_json_data,
    }
    if lag in funcs:
        return funcs[lag](text)

    # æå– ``` åŒ…è£¹çš„ä»£ç å—
    code_blocks = re.findall(r'```(.*?)```', text, re.DOTALL)
    if lag:
        code_blocks = [block for block in code_blocks if block.startswith(lag)]
        return code_blocks  # è¿‡æ»¤å‡ºæŒ‡å®šè¯­è¨€çš„ä»£ç å—

    return {k: f(text) for k, f in funcs.items()}


def extract_jsons(input_str, n=None):
    # 1,None,-1
    matches = re.findall(r'\{.*?\}', input_str, re.DOTALL)
    if not matches:
        return None
    json_objects = []
    for match in matches:
        try:
            json_objects.append(json.loads(match))
        except json.JSONDecodeError as e:
            print(f"Error decoding JSON: {e} - Skipping this fragment: {match}")

    if not json_objects:
        return None

    return json_objects if n is None else json_objects[:n]


def extract_headers(text):
    # æå– ## æˆ– ### ç­‰æ ‡é¢˜
    headers = re.findall(r'^(#{1,6})\s+(.*)', text, re.MULTILINE)
    return [{'level': len(header[0]), 'text': header[1]} for header in headers]


def extract_links(text):
    # æå– Markdown æ ¼å¼çš„é“¾æ¥ [é“¾æ¥æ–‡å­—](é“¾æ¥åœ°å€)
    links = re.findall(r'\[([^\]]+)\]\((https?:\/\/[^\s]+)\)', text)
    return [{'text': link[0], 'url': link[1]} for link in links]


def extract_bold(text):
    # æå– Markdown æ ¼å¼çš„ **ç²—ä½“**
    bold_texts = re.findall(r'\*\*(.*?)\*\*', text)
    return bold_texts


def extract_italic(text):
    # æå– Markdown æ ¼å¼çš„ __æ–œä½“__ æˆ– *æ–œä½“*
    italic_texts = re.findall(r'__(.*?)__|\*(.*?)\*', text)
    return [italic[0] or italic[1] for italic in italic_texts]  # å¤„ç†ä¸¤ä¸ªæ•è·ç»„


def ordinal_generator():
    ordinals = ['â‘ ', 'â‘¡', 'â‘¢', 'â‘£', 'â‘¤', 'â‘¥', 'â‘¦', 'â‘§', 'â‘¨', 'â‘©']
    for ordinal in ordinals:
        yield ordinal


def remove_markdown(text):
    # å»é™¤ Markdown çš„å¸¸è§æ ‡è®°
    """
    **ç²—ä½“æ–‡æœ¬**
    _æ–œä½“æ–‡æœ¬_
    ![å›¾ç‰‡æè¿°](image_url)
    [é“¾æ¥æ–‡æœ¬](url)
    ### æ ‡é¢˜æ–‡æœ¬
    > å¼•ç”¨å—
    * æ— åºåˆ—è¡¨é¡¹
    1. æœ‰åºåˆ—è¡¨é¡¹
    ~~åˆ é™¤çº¿æ–‡æœ¬~~
    __ä¸‹åˆ’çº¿æ–‡æœ¬__
    """
    text = re.sub(r'(`{1,3})(.*?)\1', r'\2', text)  # å»é™¤åå¼•å·ä»£ç å—
    text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)  # å»é™¤ç²—ä½“
    text = re.sub(r'\*(.*?)\*', r'\1', text)  # å»é™¤æ–œä½“
    text = re.sub(r'!\[.*?\]\(.*?\)', '', text)  # å»é™¤å›¾ç‰‡
    text = re.sub(r'\[.*?\]\((.*?)\)', r'\1', text)  # å»é™¤é“¾æ¥ï¼Œä½†ä¿ç•™ URL
    text = re.sub(r'#{1,6}\s*(.*)', r'\1', text)  # å»é™¤æ ‡é¢˜
    text = re.sub(r'>\s*(.*)', r'\1', text)  # å»é™¤å¼•ç”¨å—
    text = re.sub(r'(\*|-|\+)\s+(.*)', r'\2', text)  # å»é™¤æ— åºåˆ—è¡¨ç¬¦å·
    text = re.sub(r'\d+\.\s+(.*)', r'\1', text)  # å»é™¤æœ‰åºåˆ—è¡¨ç¬¦å·
    text = re.sub(r'~~(.*?)~~', r'\1', text)  # å»é™¤åˆ é™¤çº¿
    text = re.sub(r'_{2}(.*?)_{2}', r'\1', text)  # å»é™¤ä¸‹åˆ’çº¿æ ‡è®°
    text = re.sub(r'\[(.*?)\]\((.*?)\)', r'\1', text)  # å»é™¤é“¾æ¥å’Œ URL
    text = re.sub(r'\n{2,}', '\n', text)  # å°†å¤šä½™çš„ç©ºè¡Œæ›¿æ¢ä¸ºå•ä¸ªæ¢è¡Œç¬¦
    return text.strip()


def format_for_wechat(text):
    formatted_text = text
    formatted_text = re.sub(r'\*\*(.*?)\*\*', r'âœ¦\1âœ¦', formatted_text)  # **ç²—ä½“** è½¬æ¢ä¸º âœ¦ç²—ä½“âœ¦æ ·å¼
    formatted_text = re.sub(r'!!(.*?)!!', r'â—\1â—', formatted_text)  # !!é«˜äº®!! è½¬æ¢ä¸º â—ç¬¦å·åŒ…å›´
    # formatted_text = re.sub(r'__(.*?)__', r'â€»\1â€»', formatted_text)  # __æ–œä½“__ è½¬æ¢ä¸ºæ˜Ÿå·åŒ…å›´çš„æ ·å¼
    formatted_text = re.sub(r'~~(.*?)~~', r'_\1_', formatted_text)  # ~~ä¸‹åˆ’çº¿~~ è½¬æ¢ä¸ºä¸‹åˆ’çº¿åŒ…å›´
    formatted_text = re.sub(r'\^\^(.*?)\^\^', r'||\1||', formatted_text)  # ^^é‡è¦^^ è½¬æ¢ä¸º ||é‡è¦|| åŒ…å›´
    formatted_text = re.sub(r'######\s+(.*?)(\n|$)', r'[\1]\n', formatted_text)  # ###### å…­çº§æ ‡é¢˜
    formatted_text = re.sub(r'#####\s+(.*?)(\n|$)', r'ã€Š\1ã€‹\n', formatted_text)  # ##### äº”çº§æ ‡é¢˜
    formatted_text = re.sub(r'####\s+(.*?)(\n|$)', r'ã€\1ã€‘\n', formatted_text)  # #### æ ‡é¢˜è½¬æ¢
    formatted_text = re.sub(r'###\s+(.*?)(\n|$)', r'â€” \1 â€”\n', formatted_text)  # ### ä¸‰çº§æ ‡é¢˜
    formatted_text = re.sub(r'##\s+(.*?)(\n|$)', r'â€”â€” \1 â€”â€”\n', formatted_text)  # ## äºŒçº§æ ‡é¢˜
    formatted_text = re.sub(r'#\s+(.*?)(\n|$)', r'â€» \1 â€»\n', formatted_text)  # # ä¸€çº§æ ‡é¢˜
    # formatted_text = re.sub(r'```([^`]+)```',
    #                         lambda m: '\n'.join([f'ï½œ {line}' for line in m.group(1).splitlines()]) + '\n',
    #                         formatted_text)
    # formatted_text = re.sub(r'`([^`]+)`', r'ã€Œ\1ã€', formatted_text)  # `ä»£ç ` è½¬æ¢ä¸ºã€Œä»£ç ã€æ ·å¼
    # formatted_text = re.sub(r'>\s?(.*)', r'ğŸ’¬ \1', formatted_text)  # > å¼•ç”¨æ–‡æœ¬ï¼Œè½¬æ¢ä¸ºèŠå¤©ç¬¦å·åŒ…å›´
    # formatted_text = re.sub(r'^\s*[-*+]\s+', 'â€¢ ', formatted_text, flags=re.MULTILINE)  # æ— åºåˆ—è¡¨é¡¹
    # formatted_text = re.sub(r'^\s*\d+\.\s+',f"{next(ordinal_iter)} ", formatted_text, flags=re.MULTILINE)  # æœ‰åºåˆ—è¡¨é¡¹
    formatted_text = re.sub(r'\n{2,}', '\n\n', formatted_text)  # è½¬æ¢æ¢è¡Œä»¥é¿å…å¤šä½™ç©ºè¡Œ

    return formatted_text.strip()


def format_for_html(text):
    try:
        import markdown
        return markdown.markdown(text)
    except:
        return remove_markdown(text)


def extract_string(text, extract, **kwargs):
    if not extract:
        return None
    funcs = {
        "json": extract_json_from_string,
        "jsons": extract_jsons,
        "header": extract_headers,
        "links": extract_links,
        "bold": extract_bold,
        "italic": extract_italic,
        "wechat": format_for_wechat,
        "html": format_for_html
    }
    try:
        if extract in funcs:
            return funcs[extract](text, **kwargs)

        extract_type = extract.split('.')
        if extract_type[0] == 'code':
            transform = extract_code_blocks(text, lag=extract_type[1], **kwargs)
            return transform

        return {k: f(text, **kwargs) for k, f in funcs.items()}  # "type": "all"
    except Exception as e:
        print(e)

    return None


def dict_to_xml(tag, d):
    """å°†å­—å…¸è½¬æ¢ä¸º XML å­—ç¬¦ä¸²"""
    elem = ET.Element(tag)
    for key, val in d.items():
        child = ET.SubElement(elem, key)
        if isinstance(val, list):
            for item in val:
                item_elem = ET.SubElement(child, "item")
                item_elem.text = str(item)
        else:
            child.text = str(val)
    return ET.tostring(elem, encoding='unicode')


def list_to_xml(tag, lst):
    """å°†åˆ—è¡¨è½¬æ¢ä¸º XML å­—ç¬¦ä¸²"""
    elem = ET.Element(tag)
    for item in lst:
        item_elem = ET.SubElement(elem, "item")
        item_elem.text = str(item)
    return ET.tostring(elem, encoding='unicode')


def find_similar_word(target_keyword, tokens):
    max_ratio = 0
    similar_word_index = -1
    for i, token in enumerate(tokens):
        ratio = SequenceMatcher(None, target_keyword, token).ratio()
        if ratio > max_ratio:
            max_ratio = ratio
            similar_word_index = i
    return similar_word_index


def find_similar_words(query, tokens, top_n=3):
    matches = get_close_matches(query, tokens, n=top_n)
    # è®¡ç®—æ¯ä¸ªåŒ¹é…é¡¹ä¸æŸ¥è¯¢è¯çš„ç›¸ä¼¼åº¦
    results = []
    for match in matches:
        matcher = SequenceMatcher(None, query, match)
        results.append((match, matcher.ratio(), tokens.index(match)))

    return results


def contains_chinese(text):
    # æ£€æµ‹å­—ç¬¦ä¸²ä¸­æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
    chinese_pattern = re.compile(r'[\u4e00-\u9fff]')
    return bool(chinese_pattern.search(text))
    # detect(text)=='zh-cn'


def convert_to_pinyin(text):
    # æ£€æŸ¥è¾“å…¥æ˜¯å¦ä¸ºä¸­å›½åŸå¸‚åç§°ï¼ˆä»…ä¸­æ–‡ï¼‰ï¼Œç„¶åè½¬æ¢ä¸ºæ‹¼éŸ³
    if all('\u4e00' <= char <= '\u9fff' for char in text):
        return ''.join(lazy_pinyin(text))
    return text


def split_sentences(text,
                    pattern=r'(?<=[ã€‚ï¼ï¼Ÿ])|(?=\b[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+\ã€)|(?=\b[ï¼ˆ(][ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[ï¼‰)])|(?=\b\d+\ã€)',
                    merged_pattern=r'\b[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+\ã€|\b[ï¼ˆ(][ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[ï¼‰)]|\b\d+\ã€'):  # r'(?<=ã€‚|ï¼|ï¼Ÿ|\r\n)'
    """
    åˆ†å¥å‡½æ•°ï¼Œæ”¯æŒæŒ‰æ ‡ç‚¹ç¬¦å·å’Œç»“æ„åŒ–åºå·è¿›è¡Œåˆ†å¥ã€‚
    :param text: è¾“å…¥çš„æ–‡æœ¬
    :param pattern: æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…åˆ†éš”ç¬¦
    :param merged_pattern: æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ç»“æ„åŒ–åºå·ï¼ˆå¦‚â€œä¸€ã€äºŒã€ä¸‰â€æˆ–â€œï¼ˆä¸€ï¼‰â€ã€â€œ4ã€â€ï¼‰
    :return: åˆ†å‰²åçš„å¥å­åˆ—è¡¨
    """
    # åŸºäºå¥å·ã€æ„Ÿå¹å·ã€é—®å·è¿›è¡Œåˆ†å¥
    sentences = re.split(pattern, text)
    # å»æ‰ç©ºç™½å¥å­å¹¶è¿”å›
    if merged_pattern:
        merged_sentences = []
        temp = ""
        for sentence in sentences:
            if re.match(merged_pattern, sentence):
                if temp:
                    merged_sentences.append(temp.strip())
                temp = sentence
            else:
                temp += sentence
        if temp:
            merged_sentences.append(temp.strip())

        return [sentence for sentence in merged_sentences if sentence.strip()]

    return [sentence for sentence in sentences if sentence.strip()]


def split_paragraphs(sentences, max_length=512):
    paragraphs = []
    current_paragraph = ""

    for sentence in sentences:
        # å¦‚æœå½“å‰æ®µè½åŠ ä¸Šæ–°å¥å­çš„é•¿åº¦æœªè¶…æ ‡ï¼Œç›´æ¥æ·»åŠ 
        if len(current_paragraph) + len(sentence) <= max_length:
            current_paragraph += sentence
        else:
            # è¶…è¿‡ max_lengthï¼Œä¼˜å…ˆå¯»æ‰¾æ ‡ç‚¹ç¬¦å·å¤„åˆ†å‰²
            if len(current_paragraph) > 0:
                paragraphs.append(current_paragraph)
            current_paragraph = sentence

    # æ·»åŠ æœ€åä¸€æ®µ
    if current_paragraph:
        paragraphs.append(current_paragraph)

    return paragraphs


#
# def split_paragraphs(text, max_length=256):
#     sentences = split_sentences(text)
#     paragraphs = []
#     current_paragraph = ""
#
#     for sentence in sentences:
#         # å¦‚æœå½“å‰æ®µè½åŠ ä¸Šæ–°å¥å­çš„é•¿åº¦æœªè¶…æ ‡ï¼Œç›´æ¥æ·»åŠ 
#         if len(current_paragraph) + len(sentence) <= max_length:
#             current_paragraph += sentence
#         else:
#             # è¶…è¿‡ max_lengthï¼Œä¼˜å…ˆå¯»æ‰¾æ ‡ç‚¹ç¬¦å·å¤„åˆ†å‰²
#             if len(current_paragraph) > 0:
#                 paragraphs.append(current_paragraph)
#             current_paragraph = sentence
#
#     # æœ€åä¸€æ®µåŠ å…¥
#     if current_paragraph:
#         paragraphs.append(current_paragraph)
#
#     # å¤„ç†è¶…è¿‡é•¿åº¦çš„æ®µè½ï¼Œä¼˜å…ˆæŒ‰æ ‡ç‚¹æˆ–æ¢è¡Œåˆ†æ®µ
#     final_paragraphs = []
#     for paragraph in paragraphs:
#         if len(paragraph) > max_length:
#             # æŸ¥æ‰¾æ ‡ç‚¹æˆ–æ¢è¡Œç¬¦ä½ç½®
#             sub_paragraphs = re.split(r'(?<=[ã€‚ï¼ï¼Ÿ])', paragraph)
#             buffer = ""
#             for sub in sub_paragraphs:
#                 if len(buffer) + len(sub) <= max_length:
#                     buffer += sub
#                 else:
#                     final_paragraphs.append(buffer.strip())
#                     buffer = sub
#             if buffer:
#                 final_paragraphs.append(buffer.strip())
#         else:
#             final_paragraphs.append(paragraph.strip())
#
#     return final_paragraphs

# å®ç°å°åˆ°å¤§åˆ†å—é€»è¾‘
def organize_segments(tokens, small_chunk_size: int = 175, large_chunk_size: int = 512, overlap: int = 20):
    '''
    å°å—é€‚åˆç”¨äºæŸ¥è¯¢åŒ¹é…ï¼Œæé«˜æŸ¥è¯¢çš„ç²¾å‡†åº¦ã€‚
    å¤§å—åˆ’åˆ†ï¼Œå°†åŒ…å«ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å¤šä¸ªå°å—åˆå¹¶ä¸ºè¾ƒå¤§çš„ç‰‡æ®µã€‚
    æ»‘åŠ¨çª—å£ï¼šä¸ºäº†ä¿æŒä¸Šä¸‹æ–‡å…³ç³»ï¼Œåœ¨å°å—å’Œå¤§å—ä¹‹é—´æ·»åŠ ä¸€å®šçš„é‡å åŒºåŸŸï¼Œç¡®ä¿è¾¹ç¼˜ä¿¡æ¯ä¸ä¸¢å¤±ã€‚è¿™æ ·ï¼ŒæŸ¥è¯¢ç»“æœèƒ½ä¿æŒæ›´é«˜çš„è¿è´¯æ€§ã€‚
    '''

    # å°å—åˆ†å‰²
    small_chunks = []
    for i in range(0, len(tokens), small_chunk_size - overlap):
        small_chunks.append(tokens[i:i + small_chunk_size])

    # ç»„ç»‡å¤§ç‰‡æ®µ
    large_chunks = []
    for i in range(0, len(small_chunks), large_chunk_size // small_chunk_size):
        large_chunk = []
        for j in range(i, min(i + large_chunk_size // small_chunk_size, len(small_chunks))):
            large_chunk.extend(small_chunks[j])
        large_chunks.append(large_chunk[:large_chunk_size])

    return small_chunks, large_chunks


# æ”¯æŒçš„æ‰©å±•å
def get_local_suffix(folder_path, supported_suffix=None, recursive=False):
    supported_extensions = (ext.lower() for ext in supported_suffix or [".jpg", ".jpeg", ".png", ".bmp"])
    folder = Path(folder_path)
    if not folder.is_dir():
        raise ValueError(f"The path '{folder_path}' is not a valid directory.")
    pattern = "**/*" if recursive else "*"
    return [str(f_path) for f_path in folder.glob(pattern) if f_path.suffix.lower() in supported_extensions]


def get_file_type(object_name: str) -> str:
    """
    æ ¹æ®æ–‡ä»¶åæˆ–è·¯å¾„åˆ¤æ–­æ–‡ä»¶ç±»å‹ã€‚

    :param object_name: æ–‡ä»¶åæˆ–è·¯å¾„
    :return: æ–‡ä»¶ç±»å‹ï¼ˆå¦‚ 'image', 'audio', 'video', 'text', 'compressed', '*'ï¼‰
    """
    if not object_name:
        return ""

    _, file_extension = os.path.splitext(object_name.lower())

    # å®šä¹‰æ–‡ä»¶ç±»å‹åˆ†ç±»
    file_types = {
        "image": [".png", ".jpg", ".jpeg", ".gif", ".bmp", ".svg", ".webp", ".tiff", ".heic", ".heif"],
        "audio": [".mp3", ".wav", ".ogg", ".aac", ".flac", ".m4a"],
        "video": [".mp4", ".avi", ".mkv", ".mov", ".wmv", ".flv", ".webm", ".3gp"],
        "text": [".txt", ".csv", ".md", ".html", ".json", ".xml"],
        "document": [".pdf", ".doc", ".docx", ".xls", ".xlsx", ".ppt", ".pptx", ".numbers"],
        "compressed": [".zip", ".rar", ".7z", ".tar", ".gz", ".bz2"],
        "code": [".py", ".java", ".c", ".cpp", ".js", ".ts", ".html", ".css", ".sql"]
    }

    for file_type, extensions in file_types.items():
        if file_extension in extensions:
            return file_type

    return "*"

def get_file_type_wx(object_name: str) -> str:
    if not object_name:  # object_name.endswith()
        return ""
    '''
    æ–‡æ¡£ï¼šDOCã€DOCXã€XLSã€XLSXã€PPTã€PPTXã€PDFã€Numbersã€CSV
    å›¾ç‰‡ï¼šJPGã€JPG2ã€PNGã€GIFã€WEBPã€HEICã€HEIFã€BMPã€PCDã€TIFF
    æ–‡ä»¶ä¸Šä¼ å¤§å°é™åˆ¶ï¼šæ¯ä¸ªæ–‡ä»¶æœ€å¤§512MBã€‚
    '''
    _, file_extension = os.path.splitext(object_name.lower())
    # æ ¹æ®æ–‡ä»¶åç¼€åˆ¤æ–­ç±»å‹
    if file_extension in [".png", ".jpg", ".jpeg", ".gif", ".bmp", ".svg", ".webp"]:
        return "image"
    elif file_extension in [".mp3", ".wav", ".ogg", ".aac", ".flac"]:
        return "audio"
    elif file_extension in [".mp4", ".avi", ".mkv", ".mov", ".wmv", ".flv", ".webm"]:
        return "video"
    elif file_extension in [".pdf", ".doc", ".docx", ".xls", ".xlsx", ".ppt", ".pptx", ".txt", ".csv",
                            '.zip', '.rar', '.html']:
        return "*"
    return ""


def format_date(date_str):
    # ç›´æ¥ä½¿ç”¨ strptime æ¥è§£ææ—¥æœŸå¹¶æ ¼å¼åŒ–ä¸ºç›®æ ‡æ ¼å¼
    return datetime.strptime(date_str, "%Y/%m/%d %H:%M:%S").date().strftime("%Y-%m-%d")


class Url:
    def __init__(this, host, path, schema):
        this.host = host
        this.path = path
        this.schema = schema
        pass


def parse_url(requset_url):
    stidx = requset_url.index("://")
    host = requset_url[stidx + 3:]
    schema = requset_url[:stidx + 3]
    edidx = host.index("/")
    if edidx <= 0:
        raise Exception("invalid request url:" + requset_url)
    path = host[edidx:]
    host = host[:edidx]
    return Url(host, path, schema)


def format_date_type(date=None):
    # å¦‚æœæ²¡æœ‰ä¼ å…¥æ—¥æœŸï¼Œä½¿ç”¨å½“å‰æ—¥æœŸ
    if not date:
        date = datetime.now()
    elif isinstance(date, str):
        supported_formats = [
            "%Y-%m-%d",
            "%Y/%m/%d",
            "%Y-%m-%d %H:%M:%S",
            "%Y/%m/%d %H:%M:%S",
        ]
        for date_format in supported_formats:
            try:
                date = datetime.strptime(date, date_format)
                break
            except ValueError:
                continue
        else:
            raise ValueError(f"Invalid date format: {date}. Supported formats are {supported_formats}.")

    return date


def get_times_shift(days_shift: int = 0, hours_shift: int = 0):
    '''
    :param days_shift: åç§»çš„å¤©æ•°ï¼Œ>0 è¡¨ç¤ºæœªæ¥ï¼Œ<0 è¡¨ç¤ºè¿‡å»ï¼Œ0 è¡¨ç¤ºå½“å‰æ—¥æœŸã€‚
    :param hours_shift: åç§»çš„å°æ—¶æ•°ï¼Œ>0 è¡¨ç¤ºæœªæ¥ï¼Œ<0 è¡¨ç¤ºè¿‡å»ï¼Œ0 è¡¨ç¤ºå½“å‰æ—¶é—´ã€‚
    :return: æ ¼å¼åŒ–åçš„æ—¶é—´ï¼Œæ ¼å¼ä¸º 'YYYY-MM-DD HH:MM:SS'ã€‚
    '''
    current_datetime = datetime.now()
    adjusted_time = current_datetime + timedelta(days=days_shift, hours=hours_shift)
    return adjusted_time.strftime('%Y-%m-%d %H:%M:%S')


def get_day_range(date=None, shift: int = 0, count: int = 1):
    date = format_date_type(date)
    start_date = date - timedelta(days=shift)
    end_date = start_date + timedelta(days=count)
    return start_date.strftime("%Y-%m-%d"), end_date.strftime("%Y-%m-%d")


def get_week_range(date=None, shift: int = 0, count: int = 1):
    """
    è·å–æŒ‡å®šæ—¥æœŸæ‰€åœ¨å‘¨çš„å¼€å§‹å’Œç»“æŸæ—¥æœŸã€‚
    æ”¯æŒé€šè¿‡ shift å‚æ•°åç§»å‘¨ã€‚

    :param date: æŒ‡å®šçš„æ—¥æœŸï¼ˆé»˜è®¤ä¸ºå½“å‰æ—¥æœŸï¼‰ã€‚
    :param shift: åç§»å‘¨æ•°ï¼Œ>0 è¡¨ç¤ºæœªæ¥çš„å‘¨ï¼Œ<0 è¡¨ç¤ºè¿‡å»çš„å‘¨ï¼Œ0 è¡¨ç¤ºå½“å‰å‘¨ã€‚
    :param count: æ§åˆ¶è¿”å›çš„å‘¨æ•°èŒƒå›´ï¼Œé»˜è®¤ä¸º 1ï¼Œè¡¨ç¤ºè¿”å›ä¸€ä¸ªå‘¨çš„æ—¥æœŸèŒƒå›´ã€‚
    :return: è¿”å›æŒ‡å®šå‘¨çš„å¼€å§‹å’Œç»“æŸæ—¥æœŸï¼Œæ ¼å¼ä¸º ('YYYY-MM-DD', 'YYYY-MM-DD')
    """
    date = format_date_type(date)
    # æ ¹æ® shift å‚æ•°è°ƒæ•´æ—¥æœŸ
    date = date + relativedelta(weeks=shift)
    # è·å–ä»Šå¤©æ˜¯å‘¨å‡  (0 æ˜¯å‘¨ä¸€, 6 æ˜¯å‘¨æ—¥)
    weekday = date.weekday()
    # è®¡ç®—å‘¨ä¸€çš„æ—¥æœŸ (å¼€å§‹æ—¥æœŸ)
    start_of_week = date - timedelta(days=weekday)
    # è®¡ç®—å‘¨æ—¥çš„æ—¥æœŸ (ç»“æŸæ—¥æœŸ)
    # end_of_week = start_of_week + timedelta(days=6)

    end_date = start_of_week + timedelta(weeks=count) - timedelta(days=1)  # start_of_week + timedelta(days=6)

    return start_of_week.strftime("%Y-%m-%d"), end_date.strftime("%Y-%m-%d")


def get_month_range(date=None, shift: int = 0, count: int = 1):
    """
    è·å–æŒ‡å®šæ—¥æœŸæ‰€åœ¨æœˆçš„å¼€å§‹å’Œç»“æŸæ—¥æœŸã€‚
    æ”¯æŒé€šè¿‡ shift å‚æ•°åç§»æœˆæ•°ï¼Œå’Œé€šè¿‡ count æ§åˆ¶è¿”å›çš„æœˆä»½èŒƒå›´ã€‚

    :param date: æŒ‡å®šçš„æ—¥æœŸï¼ˆé»˜è®¤ä¸ºå½“å‰æ—¥æœŸï¼‰ã€‚
    :param shift: åç§»çš„æœˆæ•°ï¼Œ>0 è¡¨ç¤ºæœªæ¥çš„æœˆï¼Œ<0 è¡¨ç¤ºè¿‡å»çš„æœˆï¼Œ0 è¡¨ç¤ºå½“å‰æœˆã€‚
    :param count: æ§åˆ¶è¿”å›çš„æœˆä»½èŒƒå›´ï¼Œé»˜è®¤ä¸º 1ï¼Œè¡¨ç¤ºè¿”å›ä¸€ä¸ªæœˆçš„å¼€å§‹å’Œç»“æŸæ—¥æœŸã€‚
    :return: è¿”å›æŒ‡å®šæœˆä»½çš„å¼€å§‹å’Œç»“æŸæ—¥æœŸï¼Œæ ¼å¼ä¸º ('YYYY-MM-DD', 'YYYY-MM-DD')
      """
    date = format_date_type(date)
    # æ ¹æ® shift å‚æ•°è°ƒæ•´æ—¥æœŸ
    start_date = (date + relativedelta(months=shift)).replace(day=1)
    # è®¡ç®—ä¸‹ä¸ªæœˆçš„ç¬¬ä¸€å¤©ï¼Œç„¶åå‡å»ä¸€å¤©
    end_date = (start_date + relativedelta(months=count)).replace(day=1) - timedelta(days=1)  # + timedelta(days=32)
    return start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')  # '%Y-%m-01'


def get_quarter_range(date=None, shift: int = 0, count: int = 1):
    """
    è·å–æŒ‡å®šæ—¥æœŸæ‰€åœ¨å­£åº¦çš„å¼€å§‹å’Œç»“æŸæ—¥æœŸã€‚
    æ”¯æŒé€šè¿‡ shift å‚æ•°åç§»å­£åº¦æ•°ï¼Œå’Œé€šè¿‡ count æ§åˆ¶è¿”å›çš„å­£åº¦èŒƒå›´ã€‚

    :param date: æŒ‡å®šçš„æ—¥æœŸï¼ˆé»˜è®¤ä¸ºå½“å‰æ—¥æœŸï¼‰ã€‚
    :param shift: åç§»çš„å­£åº¦æ•°ï¼Œ>0 è¡¨ç¤ºæœªæ¥çš„å­£åº¦ï¼Œ<0 è¡¨ç¤ºè¿‡å»çš„å­£åº¦ï¼Œ0 è¡¨ç¤ºå½“å‰å­£åº¦ã€‚
    :param count: æ§åˆ¶è¿”å›çš„å­£åº¦èŒƒå›´ï¼Œé»˜è®¤ä¸º 1ï¼Œè¡¨ç¤ºè¿”å›ä¸€ä¸ªå­£åº¦çš„å¼€å§‹å’Œç»“æŸæ—¥æœŸã€‚
    :return: è¿”å›æŒ‡å®šå­£åº¦çš„å¼€å§‹å’Œç»“æŸæ—¥æœŸï¼Œæ ¼å¼ä¸º ('YYYY-MM-DD', 'YYYY-MM-DD')
    """
    date = format_date_type(date)

    # ç¡®å®šå½“å‰æ—¥æœŸæ‰€åœ¨å­£åº¦çš„èµ·å§‹æœˆä»½
    start_month = 3 * ((date.month - 1) // 3) + 1
    start_date = (date.replace(month=start_month, day=1)
                  + relativedelta(months=3 * shift))

    # è®¡ç®—å­£åº¦ç»“æŸæ—¥æœŸ
    end_date = (start_date + relativedelta(months=3 * count)).replace(day=1) - timedelta(days=1)

    return start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')


def get_quarter_month_range(date=None, shift: int = 0, count: int = 1):
    """
    è·å–æŒ‡å®šæ—¥æœŸæ‰€åœ¨å­£åº¦çš„æœˆä»½èŒƒå›´ã€‚
    æ”¯æŒé€šè¿‡ shift å‚æ•°åç§»å­£åº¦æ•°ï¼Œå’Œé€šè¿‡ count æ§åˆ¶è¿”å›çš„å­£åº¦èŒƒå›´ã€‚

    :param date: æŒ‡å®šçš„æ—¥æœŸï¼ˆé»˜è®¤ä¸ºå½“å‰æ—¥æœŸï¼‰ã€‚
    :param shift: åç§»å­£åº¦æ•°ï¼Œ>0 è¡¨ç¤ºæœªæ¥çš„å­£åº¦ï¼Œ<0 è¡¨ç¤ºè¿‡å»çš„å­£åº¦ï¼Œ0 è¡¨ç¤ºå½“å‰å­£åº¦ã€‚
    :param count: æ§åˆ¶è¿”å›çš„å­£åº¦èŒƒå›´ï¼Œé»˜è®¤ä¸º 1ï¼Œè¡¨ç¤ºè¿”å›ä¸€ä¸ªå­£åº¦çš„å¼€å§‹å’Œç»“æŸæ—¥æœŸã€‚
    :return: è¿”å›å­£åº¦çš„å¼€å§‹æœˆå’Œç»“æŸæœˆä»¥åŠèµ·å§‹å¹´ä»½ï¼Œæ ¼å¼ä¸º ('YYYY','MM', 'MM')
    """
    date = format_date_type(date)

    current_year = date.year

    # è®¡ç®—å½“å‰å­£åº¦çš„èµ·å§‹æœˆä»½
    quarter_start = (date.month - 1) // 3 * 3 + 1

    # æ ¹æ® shift åç§»å­£åº¦
    quarter_start += shift * 3

    # å¤„ç†è·¨å¹´æƒ…å†µï¼šå¦‚æœèµ·å§‹æœˆä»½è¶…å‡ºäº†12æœˆï¼Œéœ€è¦è°ƒæ•´å¹´ä»½
    if quarter_start > 12:
        quarter_start -= 12
        current_year += 1
    elif quarter_start < 1:
        quarter_start += 12
        current_year -= 1

    # è®¡ç®—å­£åº¦çš„ç»“æŸæœˆä»½
    quarter_end = quarter_start + 3 * count - 1

    # å¤„ç†ç»“æŸæœˆä»½è·¨å¹´æƒ…å†µï¼šå¦‚æœç»“æŸæœˆä»½è¶…è¿‡12æœˆï¼Œéœ€è¦è°ƒæ•´å¹´ä»½
    if quarter_end > 12:
        quarter_end -= 12

    return current_year, quarter_start, quarter_end


def get_year_range(date=None, shift: int = 0, count: int = 1):
    """
    è·å–æŒ‡å®šæ—¥æœŸæ‰€åœ¨å¹´çš„å¼€å§‹å’Œç»“æŸæ—¥æœŸã€‚
    æ”¯æŒé€šè¿‡ shift å‚æ•°åç§»å¹´æ•°ï¼Œå’Œé€šè¿‡ count æ§åˆ¶è¿”å›çš„å¹´åº¦èŒƒå›´ã€‚

    :param date: æŒ‡å®šçš„æ—¥æœŸï¼ˆé»˜è®¤ä¸ºå½“å‰æ—¥æœŸï¼‰ã€‚
    :param shift: åç§»çš„å¹´æ•°ï¼Œ>0 è¡¨ç¤ºæœªæ¥çš„å¹´ï¼Œ<0 è¡¨ç¤ºè¿‡å»çš„å¹´ï¼Œ0 è¡¨ç¤ºå½“å‰å¹´ã€‚
    :param count: æ§åˆ¶è¿”å›çš„å¹´åº¦èŒƒå›´ï¼Œé»˜è®¤ä¸º 1ï¼Œè¡¨ç¤ºè¿”å›ä¸€å¹´çš„å¼€å§‹å’Œç»“æŸæ—¥æœŸã€‚
    :return: è¿”å›æŒ‡å®šå¹´çš„å¼€å§‹å’Œç»“æŸæ—¥æœŸï¼Œæ ¼å¼ä¸º ('YYYY-MM-DD', 'YYYY-MM-DD')
    """
    date = format_date_type(date)

    # è®¡ç®—å¹´ä»½çš„å¼€å§‹æ—¥æœŸ
    start_date = date.replace(month=1, day=1) + relativedelta(years=shift)

    # è®¡ç®—å¹´ä»½çš„ç»“æŸæ—¥æœŸ
    end_date = (start_date + relativedelta(years=count)).replace(day=1, month=1) - timedelta(days=1)

    return start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')


def get_half_year_range(date=None, shift: int = 0, count: int = 1):
    """
    è·å–æŒ‡å®šæ—¥æœŸæ‰€åœ¨çš„åŠå¹´ï¼ˆå‰åŠå¹´æˆ–ååŠå¹´ï¼‰èŒƒå›´ã€‚
    æ”¯æŒé€šè¿‡ shift å‚æ•°åç§»åŠå¹´æ•°ï¼Œå’Œé€šè¿‡ count æ§åˆ¶è¿”å›çš„åŠå¹´æ•°èŒƒå›´ã€‚

    :param date: æŒ‡å®šçš„æ—¥æœŸï¼ˆé»˜è®¤ä¸ºå½“å‰æ—¥æœŸï¼‰ã€‚
    :param shift: åŠå¹´åç§»é‡ï¼Œ0 è¡¨ç¤ºå½“å‰åŠå¹´ï¼Œ-1 è¡¨ç¤ºå‰ä¸€åŠå¹´ï¼Œ1 è¡¨ç¤ºä¸‹ä¸€åŠå¹´ã€‚
    :param count: è¿”å›çš„åŠå¹´èŒƒå›´ï¼Œé»˜è®¤ä¸º 1ï¼Œè¡¨ç¤ºè¿”å›ä¸€ä¸ªåŠå¹´çš„å¼€å§‹å’Œç»“æŸæ—¥æœŸã€‚
    :return: è¿”å›æŒ‡å®šåŠå¹´çš„å¼€å§‹å’Œç»“æŸæ—¥æœŸï¼Œæ ¼å¼ä¸º ('YYYY-MM-DD', 'YYYY-MM-DD')
    """
    date = format_date_type(date)

    # åˆ¤æ–­å½“å‰æ˜¯å‰åŠå¹´è¿˜æ˜¯ååŠå¹´
    if date.month <= 6:
        start_date = date.replace(month=1, day=1)
    else:
        start_date = date.replace(month=7, day=1)

    # è°ƒæ•´æ—¥æœŸåˆ°æŒ‡å®šçš„åŠå¹´
    start_date += relativedelta(months=6 * shift)
    # è®¡ç®—åŠå¹´ç»“æŸæ—¥æœŸ
    end_date = (start_date + relativedelta(months=6 * count)).replace(day=1) - timedelta(days=1)

    return start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')


def date_range_calculator(period_type: str, date=None, shift: int = 0, count: int = 1) -> dict:
    """
    è®¡ç®—åŸºäºå‚è€ƒæ—¥æœŸçš„æ—¶é—´èŒƒå›´ã€‚

    :param period_type: æ—¶é—´å‘¨æœŸç±»å‹ï¼Œ'days'ã€'weeks'ã€'months' ç­‰
    :param date: åŸºå‡†æ—¥æœŸï¼Œæ ¼å¼ä¸º 'YYYY-MM-DD'
    :param shift: åŠå¹´åç§»é‡ï¼Œ0 è¡¨ç¤ºå½“å‰åŠå¹´ï¼Œ-1 è¡¨ç¤ºå‰ä¸€åŠå¹´ï¼Œ1 è¡¨ç¤ºä¸‹ä¸€åŠå¹´ã€‚
    :param count: æ—¶é—´å‘¨æœŸæ•°é‡ï¼Œè¡¨ç¤ºä»å‚è€ƒæ—¥æœŸå‘å‰æˆ–å‘åçš„æ—¶é•¿
    :return: è¿”å›è®¡ç®—å‡ºçš„æ—¥æœŸèŒƒå›´ï¼ŒåŒ…å« 'start_date' å’Œ 'end_date'
    """
    period_map = {'days': get_day_range,
                  'weeks': get_week_range,
                  'month': get_month_range,
                  'quarters': get_quarter_range,
                  'half_year': get_half_year_range,
                  'year': get_year_range,
                  }

    handler = period_map.get(period_type)
    if handler:
        start_date, end_date = handler(date, shift, count)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ—¶é—´å•ä½: {period_type}")

    # è¿”å›ç»“æœå­—å…¸ï¼ŒåŒ…å«å¼€å§‹å’Œç»“æŸæ—¥æœŸ
    return {'start_date': start_date, 'end_date': end_date}


class BM25:
    def __init__(self, corpus, k1=1.5, b=0.75):
        self.k1 = k1
        self.b = b
        self.corpus = [jieba.lcut(doc) for doc in corpus]  # ä½¿ç”¨ jieba å¯¹æ–‡æ¡£è¿›è¡Œåˆ†è¯
        self.doc_lengths = [len(doc) for doc in self.corpus]
        self.avg_doc_length = sum(self.doc_lengths) / len(self.doc_lengths)
        self.doc_count = len(self.corpus)
        self.doc_term_freqs = [Counter(doc) for doc in self.corpus]
        self.inverted_index = self.build_inverted_index()
        self.idf_cache = {}  # å¢åŠ ä¸€ä¸ª IDF ç¼“å­˜ï¼Œæé«˜æ•ˆç‡

    def build_inverted_index(self):
        inverted_index = {}
        for doc_id, doc_term_freq in enumerate(self.doc_term_freqs):
            for term, freq in doc_term_freq.items():
                if term not in inverted_index:
                    inverted_index[term] = []
                inverted_index[term].append((doc_id, freq))
        return inverted_index

    def idf(self, term):
        if term in self.idf_cache:
            return self.idf_cache[term]
        doc_freq = len(self.inverted_index.get(term, []))
        if doc_freq == 0:
            self.idf_cache[term] = 0
        else:
            self.idf_cache[term] = math.log((self.doc_count - doc_freq + 0.5) / (doc_freq + 0.5) + 1.0)
        return self.idf_cache[term]

    def bm25_score(self, query_terms, doc_id):
        score = 0
        doc_length = self.doc_lengths[doc_id]
        for term in query_terms:
            tf = self.doc_term_freqs[doc_id].get(term, 0)
            idf = self.idf(term)
            numerator = tf * (self.k1 + 1)
            denominator = tf + self.k1 * (1 - self.b + self.b * (doc_length / self.avg_doc_length))
            score += idf * (numerator / denominator)
        return score

    def rank_documents(self, query, sort=True, normalize=False):
        query_terms = list(jieba.cut(query))  # å¯¹æŸ¥è¯¢è¿›è¡Œåˆ†è¯
        scores = [(doc_id, self.bm25_score(query_terms, doc_id)) for doc_id in range(self.doc_count)]
        if normalize:
            max_score = max(scores, key=lambda x: x[1])[1]
            min_score = min(scores, key=lambda x: x[1])[1]
            if max_score != min_score:
                scores = [(doc_id, (score - min_score) / (max_score - min_score)) for doc_id, score in scores]

        return sorted(scores, key=lambda x: x[1], reverse=True) if sort else scores


# class BM25:
#     def __init__(self, corpus, k1=1.5, b=0.75):
#         self.k1 = k1
#         self.b = b
#         self.corpus = [list(jieba.cut(doc)) for doc in corpus]  # doc.split()
#         self.N = len(self.corpus)  # è¯­æ–™åº“ä¸­æ–‡æ¡£æ€»æ•°
#         self.avgdl = sum(len(doc) for doc in self.corpus) / self.N  # æ–‡æ¡£çš„å¹³å‡é•¿åº¦
#         self.df = self._calculate_df()  # æ¯ä¸ªè¯é¡¹çš„æ–‡æ¡£é¢‘ç‡
#         self.idf = self._calculate_idf()  # æ¯ä¸ªè¯é¡¹çš„é€†æ–‡æ¡£é¢‘ç‡
#
#     def _calculate_df(self):
#         """è®¡ç®—è¯é¡¹çš„æ–‡æ¡£é¢‘ç‡"""
#         df = {}
#         for doc in self.corpus:
#             unique_words = set(doc)
#             for word in unique_words:
#                 df[word] = df.get(word, 0) + 1
#         return df
#
#     def _calculate_idf(self):
#         """è®¡ç®—è¯é¡¹çš„é€†æ–‡æ¡£é¢‘ç‡"""
#         idf = {}
#         for word, freq in self.df.items():
#             idf[word] = math.log((self.N - freq + 0.5) / (freq + 0.5) + 1)
#         return idf
#
#     def _score(self, query, doc):
#         """è®¡ç®—å•ä¸ªæ–‡æ¡£å¯¹æŸ¥è¯¢çš„ BM25 å¾—åˆ†"""
#         score = 0.0
#         doc_len = len(doc)
#         term_frequencies = Counter(doc)
#         for word in query:
#             if word in term_frequencies:
#                 freq = term_frequencies[word]
#                 numerator = self.idf.get(word, 0) * freq * (self.k1 + 1)
#                 denominator = freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)
#                 score += numerator / denominator
#         return score
#
#     def get_scores(self, query):
#         """è®¡ç®—è¯­æ–™åº“ä¸­æ¯ä¸ªæ–‡æ¡£å¯¹æŸ¥è¯¢çš„ BM25 å¾—åˆ†"""
#         query = list(jieba.cut(query))  # ä½¿ç”¨ jieba å¯¹æŸ¥è¯¢è¿›è¡Œåˆ†è¯
#         scores = []
#         for doc in self.corpus:
#             scores.append(self._score(query, doc))
#         return scores

if __name__ == "__main__":
    # from rank_bm25 import BM25Okapi
    jieba.initialize()
    # jieba.load_userdict('data/patent_thesaurus.txt')
    corpus = [
        "å¿«é€Ÿçš„æ£•è‰²ç‹ç‹¸è·³è¿‡äº†æ‡’ç‹—",
        "æ‡’ç‹—èººä¸‹äº†",
        "ç‹ç‹¸å¾ˆå¿«é€Ÿå¹¶ä¸”è·³å¾—å¾ˆé«˜",
        "å¿«é€Ÿçš„æ£•è‰²ç‹ç‹¸",
        "çŒ«è·³è¿‡äº†ç‹—"
    ]
    query = "å¿«é€Ÿçš„ç‹ç‹¸"
    bm25 = BM25(corpus)
    scores = bm25.rank_documents(query)
    print(scores, bm25.corpus)
    # print(BM25(corpus).rank_documents(query))
